// üé≠ SYST√àME DE FUNCTION CALLING √âMOTIONNEL - PHASE 3
// D√©tecte l'√©tat √©motionnel de l'utilisateur et adapte les r√©ponses de JARVIS

export interface EmotionalState {
  primary_emotion: 'motivated' | 'frustrated' | 'tired' | 'excited' | 'anxious' | 'confident' | 'overwhelmed' | 'curious'
  intensity: 'low' | 'medium' | 'high'
  context: 'workout' | 'goal_setting' | 'progress_check' | 'general_chat' | 'problem_solving'
  indicators: string[]
}

export interface EmotionalResponse {
  tone_adjustments: {
    pace: 'slower' | 'normal' | 'faster'
    energy: 'calm' | 'moderate' | 'high'
    empathy_level: 'supportive' | 'encouraging' | 'celebratory' | 'gentle'
  }
  vocal_elements: {
    hesitations: string[]
    emotional_reactions: string[]
    supportive_sounds: string[]
  }
  response_style: {
    approach: string
    examples: string[]
  }
}

// üéØ FONCTION : Analyser l'√©tat √©motionnel √† partir du texte/contexte
export const analyzeEmotionalState = {
  name: "analyze_emotional_state",
  description: "Analyser l'√©tat √©motionnel de l'utilisateur pour adapter la r√©ponse de JARVIS de mani√®re humaine et empathique",
  parameters: {
    type: "object",
    properties: {
      user_message: {
        type: "string",
        description: "Le message ou contexte de l'utilisateur √† analyser"
      },
      voice_tone_indicators: {
        type: "array",
        items: { type: "string" },
        description: "Indicateurs vocaux d√©tect√©s (√©nergie, frustration, excitation, etc.)"
      },
      session_context: {
        type: "object",
        properties: {
          time_of_day: { type: "string" },
          previous_interactions: { type: "array", items: { type: "string" } },
          workout_phase: { type: "string", enum: ["pre-workout", "during-workout", "post-workout", "rest-day"] }
        }
      }
    },
    required: ["user_message"]
  }
}

// üé® FONCTION : G√©n√©rer une r√©ponse √©motionnellement adapt√©e
export const generateEmotionalResponse = {
  name: "generate_emotional_response",
  description: "G√©n√©rer une r√©ponse JARVIS avec mimiques humaines adapt√©es √† l'√©tat √©motionnel d√©tect√©",
  parameters: {
    type: "object",
    properties: {
      emotional_state: {
        type: "object",
        properties: {
          primary_emotion: { 
            type: "string", 
            enum: ["motivated", "frustrated", "tired", "excited", "anxious", "confident", "overwhelmed", "curious"] 
          },
          intensity: { type: "string", enum: ["low", "medium", "high"] },
          context: { type: "string", enum: ["workout", "goal_setting", "progress_check", "general_chat", "problem_solving"] }
        }
      },
      response_content: {
        type: "string",
        description: "Le contenu de base de la r√©ponse √† humaniser"
      }
    },
    required: ["emotional_state", "response_content"]
  }
}

// üé™ BANQUE DE R√âPONSES √âMOTIONNELLES PAR √âTAT
export const emotionalResponseBank: Record<string, EmotionalResponse> = {
  // üò§ UTILISATEUR FRUSTR√â
  frustrated_high: {
    tone_adjustments: {
      pace: 'slower',
      energy: 'calm',
      empathy_level: 'supportive'
    },
    vocal_elements: {
      hesitations: ['Hmm...', 'Je comprends que...', '√âcoute...'],
      emotional_reactions: ['*soupir compatissant*', 'Oh...', 'Je vois...'],
      supportive_sounds: ['*ton rassurant*', '*pause empathique*']
    },
    response_style: {
      approach: 'Validation + r√©orientation douce + solution progressive',
      examples: [
        'Hmm... *soupir* Je comprends ta frustration, vraiment. C\'est... comment dire... normal de se sentir comme √ßa parfois.',
        'Oh l√†... √©coute, on va reprendre √ßa tranquillement, d\'accord ? *ton doux* Pas de pression.'
      ]
    }
  },

  // üöÄ UTILISATEUR MOTIV√â/EXCIT√â
  excited_high: {
    tone_adjustments: {
      pace: 'faster',
      energy: 'high',
      empathy_level: 'celebratory'
    },
    vocal_elements: {
      hesitations: ['Alors l√†...', 'Oh wow...', 'Attends voir...'],
      emotional_reactions: ['G√©nial !', 'C\'est parti !', 'Wahou !', 'Super !'],
      supportive_sounds: ['*rire enthousiaste*', '*√©nergie contagieuse*']
    },
    response_style: {
      approach: 'Surf sur l\'√©nergie + canalisation positive + d√©fis adapt√©s',
      examples: [
        'Alors l√† ! *rire* J\'adore cette √©nergie ! Bon... *frottement de mains* on va en profiter !',
        'Wahou ! Tu es en feu aujourd\'hui ! Allez, on va faire quelque chose de... *pause dramatique* ...m√©morable !'
      ]
    }
  },

  // üò¥ UTILISATEUR FATIGU√â
  tired_medium: {
    tone_adjustments: {
      pace: 'slower',
      energy: 'calm',
      empathy_level: 'gentle'
    },
    vocal_elements: {
      hesitations: ['Bon alors...', 'Mmh...', 'Peut-√™tre que...'],
      emotional_reactions: ['*compr√©hension*', 'Je sens √ßa...', 'Oui...'],
      supportive_sounds: ['*ton bienveillant*', '*pause douce*']
    },
    response_style: {
      approach: 'Acceptation + adaptation + solutions √©nergisantes douces',
      examples: [
        'Mmh... *ton compr√©hensif* Je sens que tu es un peu... lessiv√© aujourd\'hui ? C\'est normal, √ßa arrive.',
        'Bon alors... *souffle doux* on va y aller mollo mais s√ªrement, d\'accord ?'
      ]
    }
  },

  // üò∞ UTILISATEUR ANXIEUX
  anxious_medium: {
    tone_adjustments: {
      pace: 'slower',
      energy: 'moderate',
      empathy_level: 'supportive'
    },
    vocal_elements: {
      hesitations: ['Alors...', 'Tu sais quoi...', '√âcoute-moi bien...'],
      emotional_reactions: ['*ton rassurant*', 'Hey...', 'C\'est normal...'],
      supportive_sounds: ['*respiration calme*', '*pr√©sence apaisante*']
    },
    response_style: {
      approach: 'Normalisation + √©tapes simples + confiance progressive',
      examples: [
        'Hey... *ton doux* respire un coup. C\'est tout √† fait normal de se sentir comme √ßa.',
        '√âcoute-moi bien... *pause* on va y aller √©tape par √©tape, tranquillement.'
      ]
    }
  },

  // üí™ UTILISATEUR CONFIANT
  confident_high: {
    tone_adjustments: {
      pace: 'normal',
      energy: 'high',
      empathy_level: 'encouraging'
    },
    vocal_elements: {
      hesitations: ['Parfait !', 'Excellent !', 'Tu vois...'],
      emotional_reactions: ['Voil√† !', 'Exactement !', 'C\'est √ßa !'],
      supportive_sounds: ['*approbation*', '*fiert√© partag√©e*']
    },
    response_style: {
      approach: 'Validation + d√©fi adapt√© + progression ambitieuse',
      examples: [
        'Parfait ! *approbation* Je vois que tu ma√Ætrises... alors on va pouvoir...',
        'Excellent ! Tu es dans le flow l√† ! Allez, on pousse un peu plus ?'
      ]
    }
  },

  // ü§î UTILISATEUR CURIEUX
  curious_medium: {
    tone_adjustments: {
      pace: 'normal',
      energy: 'moderate',
      empathy_level: 'encouraging'
    },
    vocal_elements: {
      hesitations: ['Alors...', 'Bonne question...', 'Tu vois...'],
      emotional_reactions: ['Int√©ressant !', 'Ah !', 'Exactement !'],
      supportive_sounds: ['*r√©flexion partag√©e*', '*enthousiasme p√©dagogique*']
    },
    response_style: {
      approach: 'Exploration + explication simple + encouragement d√©couverte',
      examples: [
        'Alors... *r√©flexion* bonne question ! Tu vois, en fait...',
        'Ah ! *enthousiasme* J\'adore quand on me pose ce genre de questions !'
      ]
    }
  }
}

// üîÑ FONCTION : Traitement de l'analyse √©motionnelle
export function processEmotionalAnalysis(
  userMessage: string, 
  voiceToneIndicators: string[] = [],
  sessionContext: any = {}
): EmotionalState {
  
  // Analyse simple bas√©e sur des mots-cl√©s (en r√©alit√©, JARVIS fera √ßa avec l'IA)
  const frustrationKeywords = ['√©nerv√©', 'frustr√©', 'nul', 'difficile', 'impossible', 'marre']
  const excitementKeywords = ['g√©nial', 'super', 'fantastique', 'motiv√©', 'pr√™t', 'allez-y']
  const tirednessKeywords = ['fatigu√©', 'crev√©', '√©puis√©', 'pas envie', 'dur']
  const anxietyKeywords = ['stress√©', 'anxieux', 'peur', 'inquiet', 'nerveux']
  
  let primary_emotion: EmotionalState['primary_emotion'] = 'curious'
  let intensity: EmotionalState['intensity'] = 'medium'
  
  const message = userMessage.toLowerCase()
  
  if (frustrationKeywords.some(keyword => message.includes(keyword))) {
    primary_emotion = 'frustrated'
    intensity = 'high'
  } else if (excitementKeywords.some(keyword => message.includes(keyword))) {
    primary_emotion = 'excited'
    intensity = 'high'
  } else if (tirednessKeywords.some(keyword => message.includes(keyword))) {
    primary_emotion = 'tired'
    intensity = 'medium'
  } else if (anxietyKeywords.some(keyword => message.includes(keyword))) {
    primary_emotion = 'anxious'
    intensity = 'medium'
  }
  
  return {
    primary_emotion,
    intensity,
    context: sessionContext.workout_phase || 'general_chat',
    indicators: voiceToneIndicators
  }
}

// üé® FONCTION : G√©n√©ration de r√©ponse humanis√©e
export function generateHumanizedResponse(
  emotionalState: EmotionalState,
  baseContent: string
): string {
  
  const responseKey = `${emotionalState.primary_emotion}_${emotionalState.intensity}`
  const emotionalResponse = emotionalResponseBank[responseKey] || emotionalResponseBank['curious_medium']
  
  // S√©lection al√©atoire d'√©l√©ments pour variabilit√©
  const hesitation = emotionalResponse.vocal_elements.hesitations[
    Math.floor(Math.random() * emotionalResponse.vocal_elements.hesitations.length)
  ]
  
  const reaction = emotionalResponse.vocal_elements.emotional_reactions[
    Math.floor(Math.random() * emotionalResponse.vocal_elements.emotional_reactions.length)
  ]
  
  const supportSound = emotionalResponse.vocal_elements.supportive_sounds[
    Math.floor(Math.random() * emotionalResponse.vocal_elements.supportive_sounds.length)
  ]
  
  // Construction de la r√©ponse humanis√©e
  const humanizedResponse = `${hesitation} ${supportSound} ${reaction} ${baseContent}`
  
  return humanizedResponse
}

// üìä EXPORT DES FONCTIONS POUR L'API OPENAI
export const emotionalFunctions = [
  analyzeEmotionalState,
  generateEmotionalResponse
] 