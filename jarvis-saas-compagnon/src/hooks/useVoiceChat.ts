import { useState, useRef, useCallback, useEffect } from 'react'
import { AudioState } from '@/types/kiosk'
// üóëÔ∏è SUPPRIM√â - Remplac√© par Prisma tracking
// import { whisperParallelTracker } from '@/lib/whisper-parallel-tracker' // üóëÔ∏è SUPPRIM√â - OpenAI fait tout

interface VoiceChatConfig {
  gymSlug: string
  memberId?: string
  language?: 'fr' | 'en' | 'es'
  // üîß BUGFIX: Ajouter memberData pour contourner le getMemberData hardcod√©
  memberData?: {
    first_name: string
    last_name: string
    member_preferences?: {
      goals: string[]
      favorite_activities: string[]
    }
    last_visit?: string
    membership_type?: string
    total_visits?: number
  }
  onStatusChange?: (status: 'idle' | 'connecting' | 'connected' | 'listening' | 'speaking' | 'error' | 'reconnecting') => void
  onTranscriptUpdate?: (transcript: string, isFinal: boolean) => void
  onError?: (error: string) => void
  onSessionCreated?: (sessionId: string, memberId?: string, gymId?: string) => void
}

interface VoiceChatSession {
  client_secret: { value: string }
  session_id: string
  expires_at: string
  member_id?: string
  gym_id?: string
}

// Configuration de reconnexion
const RECONNECT_CONFIG = {
  maxAttempts: 5,
  baseDelay: 1000, // 1 seconde
  maxDelay: 30000, // 30 secondes
  backoffMultiplier: 2
}

export function useVoiceChat(config: VoiceChatConfig) {
  
  const [audioState, setAudioState] = useState<AudioState>({
    isRecording: false,
    isPlaying: false,
    micPermission: 'prompt',
    audioLevel: 0
  })
  
  const [isConnected, setIsConnected] = useState(false)
  const [currentTranscript, setCurrentTranscript] = useState('')
  
  // üîß STABILIT√â SESSION - √âviter les d√©connexions accidentelles  
  const lastActivityRef = useRef<number>(Date.now())
  const stabilityTimeoutRef = useRef<NodeJS.Timeout | null>(null)
  const [status, setStatus] = useState<'idle' | 'connecting' | 'connected' | 'listening' | 'speaking' | 'error' | 'reconnecting'>('idle')
  const [connectionQuality, setConnectionQuality] = useState<'excellent' | 'good' | 'poor' | 'unknown'>('unknown')

  // üìä √âtats de tracking de session
  const sessionTrackingRef = useRef<{
    sessionId: string | null
    gymId: string | null
    franchiseId: string | null
    startTime: Date | null
    textInputTokens: number
    textOutputTokens: number
    audioInputSeconds: number
    audioOutputSeconds: number
    currentUserSpeech?: string
    errorOccurred: boolean
    transcriptHistory: string[]
    speechStartTime?: number
  }>({
    sessionId: null,
    gymId: null,
    franchiseId: null,
    startTime: null,
    textInputTokens: 0,
    textOutputTokens: 0,
    audioInputSeconds: 0,
    audioOutputSeconds: 0,
    errorOccurred: false,
    transcriptHistory: []
  })
  
  // Refs pour √©viter les re-cr√©ations
  const peerConnectionRef = useRef<RTCPeerConnection | null>(null)
  const dataChannelRef = useRef<RTCDataChannel | null>(null)
  const audioElementRef = useRef<HTMLAudioElement | null>(null)
  const sessionRef = useRef<VoiceChatSession | null>(null)
  const isConnectingRef = useRef(false)
  const configRef = useRef(config)
  
  // Refs pour la reconnexion
  const reconnectAttempts = useRef(0)
  const reconnectTimeoutRef = useRef<NodeJS.Timeout | null>(null)
  
  // Buffer pour les transcripts partiels
  const transcriptBufferRef = useRef('')
  
  // Mettre √† jour la config de r√©f√©rence
  useEffect(() => {
    configRef.current = config
  }, [config])

  // Fonction utilitaire pour changer le status
  const updateStatus = useCallback((newStatus: typeof status) => {
    setStatus(newStatus)
    configRef.current.onStatusChange?.(newStatus)
    
    // üîß STABILIT√â: Marquer l'activit√© pour √©viter les timeouts
    lastActivityRef.current = Date.now()
  }, [])
  
  // üîß STABILIT√â SESSION - Fonction de maintien en vie
  const maintainSessionStability = useCallback(() => {
    if (!isConnected) return
    
    const timeSinceActivity = Date.now() - lastActivityRef.current
    
    // Si pas d'activit√© depuis plus de 45 secondes, marquer l'activit√©
    if (timeSinceActivity > 45000) {
      console.log('üîß [STABILIT√â] Maintien session - refresh activit√©')
      lastActivityRef.current = Date.now()
    }
    
    // Programmer le prochain check dans 20 secondes
    stabilityTimeoutRef.current = setTimeout(maintainSessionStability, 20000)
  }, [isConnected])
  
  // D√©marrer le maintien de stabilit√© quand connect√©
  useEffect(() => {
    if (isConnected) {
      lastActivityRef.current = Date.now()
      maintainSessionStability()
    } else if (stabilityTimeoutRef.current) {
      clearTimeout(stabilityTimeoutRef.current)
      stabilityTimeoutRef.current = null
    }
    
    return () => {
      if (stabilityTimeoutRef.current) {
        clearTimeout(stabilityTimeoutRef.current)
        stabilityTimeoutRef.current = null
      }
    }
  }, [isConnected, maintainSessionStability])

  // üìä Fonctions helper pour le tracking de session
  const generateSessionId = useCallback(() => {
    return `jarvis_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`
  }, [])

  const initSessionTracking = useCallback(async (gymData?: { gymId?: string; franchiseId?: string }) => {
    const sessionId = generateSessionId()
    
    sessionTrackingRef.current = {
      sessionId,
      gymId: gymData?.gymId || null,
      franchiseId: gymData?.franchiseId || null,
      startTime: new Date(),
      textInputTokens: 0,
      textOutputTokens: 0,
      audioInputSeconds: 0,
      audioOutputSeconds: 0,
      errorOccurred: false,
      transcriptHistory: []
    }

    console.log('üìä [TRACKING] Session initialis√©e:', sessionId)
  }, [generateSessionId])

     const finalizeSessionTracking = useCallback(async () => {
     const tracking = sessionTrackingRef.current
     
     // ‚úÖ CORRECTION: Ne pas traiter si aucune session n'a jamais √©t√© initialis√©e
     if (!tracking.sessionId) {
       console.log('üìä [TRACKING] Aucune session √† finaliser (pas de sessionId)')
       return
     }
     
     console.log('üìä [TRACKING] ===== D√âBUT FINALISATION SESSION =====')
     console.log('üìä [TRACKING] Donn√©es de tracking actuelles:', tracking)
     
     if (!tracking.startTime || !tracking.gymId) {
       console.error('üìä [TRACKING] ‚ùå DONN√âES INCOMPL√àTES:')
       console.error('- sessionId:', tracking.sessionId)
       console.error('- startTime:', tracking.startTime)
       console.error('- gymId:', tracking.gymId)
       console.error('- franchiseId:', tracking.franchiseId)
       return
     }

    try {
      const durationSeconds = Math.floor((Date.now() - tracking.startTime.getTime()) / 1000)
      
      // Calculer approximativement les tokens audio bas√©s sur la dur√©e
      const audioInputTokens = Math.round(tracking.audioInputSeconds * 1667 / 60) // ~1667 tokens/minute
      const audioOutputTokens = Math.round(tracking.audioOutputSeconds * 1667 / 60)

      console.log('üìä [TRACKING] Finalisation session:', {
        sessionId: tracking.sessionId,
        durationSeconds,
        audioInputTokens,
        audioOutputTokens
      })

      await trackSessionCost({
        sessionId: tracking.sessionId,
        gymId: tracking.gymId,
        franchiseId: tracking.franchiseId,
        timestamp: tracking.startTime,
        durationSeconds,
        textInputTokens: tracking.textInputTokens,
        textOutputTokens: tracking.textOutputTokens,
        audioInputTokens,
        audioOutputTokens,
        userSatisfaction: undefined, // TODO: Collecter si n√©cessaire
        errorOccurred: tracking.errorOccurred,
        endReason: tracking.errorOccurred ? 'error' : 'user_ended',
        audioInputSeconds: tracking.audioInputSeconds,
        audioOutputSeconds: tracking.audioOutputSeconds
      })

      // üéØ [INSTRUMENTATION] Finaliser la session OpenAI Realtime
      try {
        console.log('üîç [DEBUG SESSION FINALIZE] sessionRef.current:', sessionRef.current)
        console.log('üîç [DEBUG SESSION FINALIZE] sessionRef.current?.session_id:', sessionRef.current?.session_id)
        
        if (sessionRef.current?.session_id) {
          const costBreakdown = calculateSessionCost({
            durationSeconds,
            textInputTokens: tracking.textInputTokens,
            textOutputTokens: tracking.textOutputTokens,
            audioInputSeconds: tracking.audioInputSeconds,
            audioOutputSeconds: tracking.audioOutputSeconds
          })

          // TODO: Prisma endSession avec costBreakdown et durationSeconds

          console.log('üéØ [INSTRUMENTATION] Session OpenAI finalis√©e avec succ√®s')
        }
      } catch (instrumentationError) {
        console.error('‚ùå [INSTRUMENTATION] Erreur finalisation session:', instrumentationError)
        // Ne pas faire √©chouer le tracking normal
      }

      console.log('üìä [TRACKING] ‚úÖ SESSION SAUVEGARD√âE AVEC SUCC√àS!')
      console.log('üìä [TRACKING] Session ID final:', tracking.sessionId)
      console.log('üìä [TRACKING] ===== FIN FINALISATION SESSION =====')
     } catch (error) {
       console.error('üìä [TRACKING] ‚ùå ERREUR CRITIQUE SAUVEGARDE:', error)
       console.error('üìä [TRACKING] D√©tails erreur:', {
         name: error instanceof Error ? error.name : 'Unknown',
         message: error instanceof Error ? error.message : error,
         stack: error instanceof Error ? error.stack : undefined
       })
     }
  }, [])

  // üîß BUGFIX: Utiliser les donn√©es membre pass√©es directement au lieu du hardcod√©
  const getMemberData = useCallback(async () => {
    // Si on a les donn√©es membre directement, les utiliser
    if (config.memberData) {
      console.log(`üìã Utilisation des donn√©es membre pour: ${config.memberData.first_name} ${config.memberData.last_name}`)
      return config.memberData
    }
    
    // Sinon, fallback sur memberId (pour compatibilit√© future avec Supabase)
    if (!config.memberId) return null
    
    try {
      // TODO: Int√©grer avec Supabase pour r√©cup√©rer les vraies donn√©es depuis la BDD
      console.warn('‚ö†Ô∏è Fallback vers donn√©es hardcod√©es - int√©gration Supabase requise')
      return {
        first_name: 'Pierre',
        last_name: 'Martin',
        member_preferences: {
          goals: ['Perte de poids', 'Renforcement musculaire'],
          favorite_activities: ['Entra√Ænement du matin'],
        },
        last_visit: '2024-01-20'
      }
    } catch (error) {
      console.warn('Impossible de r√©cup√©rer les donn√©es membre:', error)
      return null
    }
  }, [config.memberId, config.memberData])

  // Cr√©er une session OpenAI Realtime avec token eph√©m√®re
  const createSession = useCallback(async () => {
    try {
      const memberData = await getMemberData()
      
             // üìä [TRACKING] R√©cup√©rer les infos de gym/franchise pour le tracking
       let gymData = null
       try {
         console.log('üìä [TRACKING] R√©cup√©ration infos gym pour:', config.gymSlug)
         const gymResponse = await fetch(`/api/kiosk/${config.gymSlug}`)
         console.log('üìä [TRACKING] R√©ponse gym API:', gymResponse.status, gymResponse.ok)
         
                   if (gymResponse.ok) {
            const gymInfo = await gymResponse.json()
            console.log('üìä [TRACKING] Donn√©es gym compl√®tes:', gymInfo)
            
            // ‚úÖ CORRECTION: Plusieurs fa√ßons d'extraire les IDs pour compatibilit√©
            const extractedGymId = gymInfo.data?.id || gymInfo.gym?.id || gymInfo.kiosk?.id
            const extractedFranchiseId = gymInfo.data?.franchise_id || gymInfo.gym?.franchise_id
            
            gymData = {
              gymId: extractedGymId,
              franchiseId: extractedFranchiseId
            }
            console.log('üìä [TRACKING] Infos gym extraites:', gymData)
            
            if (!gymData.gymId) {
              console.error('üìä [TRACKING] ‚ùå PROBL√àME: gymId manquant dans la r√©ponse API')
              console.error('üìä [TRACKING] Structure re√ßue:', {
                hasData: !!gymInfo.data,
                hasGym: !!gymInfo.gym,
                hasKiosk: !!gymInfo.kiosk,
                dataId: gymInfo.data?.id,
                gymId: gymInfo.gym?.id,
                kioskId: gymInfo.kiosk?.id
              })
            }
         } else {
           console.error('üìä [TRACKING] ‚ùå Erreur API gym:', gymResponse.status)
         }
       } catch (error) {
         console.error('üìä [TRACKING] ‚ùå Exception r√©cup√©ration gym:', error)
       }
      
      const response = await fetch('/api/voice/session', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          memberId: config.memberId,
          gymSlug: config.gymSlug,
          memberData,
          voice: 'verse' // Voix recommand√©e pour fran√ßais
        }),
      })

      if (!response.ok) {
        throw new Error(`Session creation failed: ${response.status}`)
      }

      const data = await response.json()
      
      console.log('üîç [DEBUG SESSION] R√©ponse API compl√®te:', data)
      console.log('üîç [DEBUG SESSION] data.session:', data.session)
      console.log('üîç [DEBUG SESSION] data.session?.id:', data.session?.id)
      
      // üìä [TRACKING] Initialiser le tracking de session
      await initSessionTracking(gymData)
      
      return data.session
    } catch (error) {
      console.error('Erreur cr√©ation session:', error)
      throw error
    }
  }, [config.memberId, config.gymSlug, getMemberData, initSessionTracking])

  // Programmer une reconnexion avec backoff exponentiel (AVANT connect pour √©viter d√©pendance circulaire)
  const scheduleReconnect = useCallback(() => {
    if (reconnectTimeoutRef.current) return

    reconnectAttempts.current++
    const delay = Math.min(
      RECONNECT_CONFIG.baseDelay * Math.pow(RECONNECT_CONFIG.backoffMultiplier, reconnectAttempts.current - 1),
      RECONNECT_CONFIG.maxDelay
    )

    console.log(`üîÑ Reconnexion programm√©e dans ${delay}ms (tentative ${reconnectAttempts.current}/${RECONNECT_CONFIG.maxAttempts})`)
    updateStatus('reconnecting')

    reconnectTimeoutRef.current = setTimeout(() => {
      reconnectTimeoutRef.current = null
      // Utiliser la r√©f√©rence directe pour √©viter d√©pendance circulaire
      connect()
    }, delay)
  }, [updateStatus])

  // Initialiser la connexion WebRTC
  const initializeWebRTC = useCallback(async (session: VoiceChatSession) => {
    try {
      // Cr√©er la peer connection
      const pc = new RTCPeerConnection({
        iceServers: [{ urls: 'stun:stun.l.google.com:19302' }]
      })
      
      peerConnectionRef.current = pc

      // Demander permission micro et ajouter le track audio
      console.log('üé§ Demande de permissions microphone...')
      
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
          sampleRate: 16000
        } 
      })
      
      console.log('‚úÖ Permissions microphone accord√©es')
      
      // Ajouter le track audio local
      stream.getTracks().forEach(track => {
        pc.addTrack(track, stream)
      })

      setAudioState(prev => ({ ...prev, micPermission: 'granted' }))

      // Cr√©er l'√©l√©ment audio pour le playback
      if (!audioElementRef.current) {
        const audioEl = document.createElement('audio')
        audioEl.autoplay = true
        audioElementRef.current = audioEl
      }

      // G√©rer les tracks audio distants (r√©ponses IA)
      pc.ontrack = (event) => {
        console.log('üéµ Track audio re√ßu depuis OpenAI')
        if (audioElementRef.current && event.streams[0]) {
          audioElementRef.current.srcObject = event.streams[0]
          setAudioState(prev => ({ ...prev, isPlaying: true }))
        }
      }

      // Cr√©er le data channel pour les √©v√©nements
      const dc = pc.createDataChannel('oai-events')
      dataChannelRef.current = dc

      // G√©rer les messages du data channel
      dc.onopen = () => {
        console.log('üì° Data channel ouvert')
        setIsConnected(true)
        updateStatus('connected')
        reconnectAttempts.current = 0
      }

      dc.onmessage = (event) => {
        try {
          const serverEvent = JSON.parse(event.data)
          handleServerEvent(serverEvent)
        } catch (error) {
          console.error('Erreur parsing √©v√©nement serveur:', error)
        }
      }

      dc.onerror = (error) => {
        console.error('Erreur data channel:', error)
        configRef.current.onError?.('Erreur de communication')
      }

      dc.onclose = () => {
        console.log('üì° Data channel ferm√©')
        setIsConnected(false)
        if (status !== 'idle') {
          updateStatus('error')
        }
      }

      // Cr√©er l'offre WebRTC
      const offer = await pc.createOffer()
      await pc.setLocalDescription(offer)

      // Envoyer l'offre √† OpenAI Realtime API
      const ephemeralKey = session.client_secret.value
      const realtimeResponse = await fetch(`https://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-12-17`, {
        method: 'POST',
        body: offer.sdp,
        headers: {
          'Authorization': `Bearer ${ephemeralKey}`,
          'Content-Type': 'application/sdp'
        },
      })

      if (!realtimeResponse.ok) {
        throw new Error(`WebRTC handshake failed: ${realtimeResponse.status}`)
      }

      // Recevoir et appliquer la r√©ponse
      const answerSdp = await realtimeResponse.text()
      const answer = {
        type: 'answer' as RTCSdpType,
        sdp: answerSdp,
      }
      await pc.setRemoteDescription(answer)

      sessionRef.current = session
      console.log('üîç [DEBUG SESSION ASSIGN] sessionRef.current assign√©:', session)
      console.log('üîç [DEBUG SESSION ASSIGN] session.session_id:', session?.session_id)
      console.log('‚úÖ Connexion WebRTC √©tablie avec OpenAI Realtime')

    } catch (error) {
      console.error('Erreur initialisation WebRTC:', error)
      throw error
    }
  }, [status, updateStatus])

  // G√©rer les √©v√©nements du serveur OpenAI
  const handleServerEvent = useCallback((event: { type: string; [key: string]: unknown }) => {
    switch (event.type) {
      case 'session.created':
        console.log('üéØ Session OpenAI cr√©√©e')
        break
        
      case 'session.updated':
        console.log('üîÑ Session OpenAI mise √† jour')
        break

      case 'input_audio_buffer.speech_started':
        console.log('üé§ D√©but de parole d√©tect√©')
        updateStatus('listening')
        setAudioState(prev => ({ ...prev, isRecording: true }))
        
        // üîß STABILIT√â: Activit√© d√©tect√©e
        lastActivityRef.current = Date.now()
        
        // üìä [TRACKING] Marquer le d√©but d'input audio
        if (sessionTrackingRef.current.sessionId) {
          sessionTrackingRef.current.speechStartTime = Date.now()
        }
        
        // üéØ [INSTRUMENTATION] Enregistrer √©v√©nement audio
        try {
          if (sessionRef.current?.session_id) {
            // TODO: Prisma recordAudioEvent speech_started
          }
        } catch (error) {
          console.error('‚ùå [INSTRUMENTATION] Erreur speech_started:', error)
        }
        break

      case 'input_audio_buffer.speech_stopped':
        console.log('ü§ê Fin de parole d√©tect√©e')
        setAudioState(prev => ({ ...prev, isRecording: false }))
        
        // üîß STABILIT√â: Activit√© d√©tect√©e
        lastActivityRef.current = Date.now()
        
        // üìä [TRACKING] Calculer la dur√©e d'input audio
        if (sessionTrackingRef.current.sessionId && sessionTrackingRef.current.speechStartTime) {
          const duration = (Date.now() - sessionTrackingRef.current.speechStartTime) / 1000
          sessionTrackingRef.current.audioInputSeconds += duration
          delete sessionTrackingRef.current.speechStartTime
        }
        
        // üéØ [INSTRUMENTATION] Enregistrer √©v√©nement audio
        try {
          if (sessionRef.current?.session_id) {
            // TODO: Prisma recordAudioEvent('speech_stopped')
          }
        } catch (error) {
          console.error('‚ùå [INSTRUMENTATION] Erreur speech_stopped:', error)
        }
        break

      case 'response.created':
        console.log('üí≠ R√©ponse IA en cours de g√©n√©ration')
        updateStatus('speaking')
        // üîß ACTIVIT√â: JARVIS parle = activit√© (pas d'inactivit√©)
        lastActivityRef.current = Date.now()
        break

      case 'response.audio_transcript.delta':
        if (event.delta) {
          transcriptBufferRef.current += event.delta
          configRef.current.onTranscriptUpdate?.(transcriptBufferRef.current, false)
          setCurrentTranscript(transcriptBufferRef.current)
          // üîß ACTIVIT√â: JARVIS parle = activit√©
          lastActivityRef.current = Date.now()
        }
        break

      case 'conversation.item.input_audio_transcription.delta':
        // üéôÔ∏è NOUVEAU: Transcription utilisateur temps r√©el (deltas)
        const deltaTranscript = (event as any).delta?.transcript as string
        if (deltaTranscript) {
          console.log('üîä [OPENAI USER] Speech delta:', deltaTranscript.substring(0, 30) + '...')
          
          // üìä [TRACKING] Ajouter au buffer pour assemblage final
          if (sessionTrackingRef.current.sessionId) {
            // Buffer les deltas pour √©viter duplication avec completed
            if (!sessionTrackingRef.current.currentUserSpeech) {
              sessionTrackingRef.current.currentUserSpeech = ''
            }
            sessionTrackingRef.current.currentUserSpeech += deltaTranscript
          }
        }
        break

      case 'conversation.item.input_audio_transcription.completed':
        // üéôÔ∏è TRANSCRIPTION UTILISATEUR FINALE
        const userTranscript = (event as any).transcript as string
        if (userTranscript) {
          console.log('üë§ [OPENAI USER] Speech captured FINAL:', userTranscript.substring(0, 50) + '...')
          
          // üìä [TRACKING] Utiliser transcript final (plus fiable que deltas)
          if (sessionTrackingRef.current.sessionId) {
            sessionTrackingRef.current.transcriptHistory.push(`USER: ${userTranscript}`)
            sessionTrackingRef.current.textInputTokens += Math.ceil(userTranscript.length / 4)
            
            // Reset buffer deltas
            delete sessionTrackingRef.current.currentUserSpeech
          }
          
          // üíæ [LOGGING] Sauver imm√©diatement en base
          try {
            if (sessionRef.current?.session_id && config.gymSlug) {
              fetch(`/api/kiosk/${config.gymSlug}/log-interaction`, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({
                  session_id: sessionRef.current.session_id,
                  member_id: sessionRef.current.member_id,
                  gym_id: sessionRef.current.gym_id,
                  speaker: 'user',
                  message_text: userTranscript,
                  conversation_turn_number: sessionTrackingRef.current.transcriptHistory.filter(t => t.startsWith('USER:')).length
                }),
                keepalive: true
              }).catch(error => console.warn('‚ö†Ô∏è Log interaction failed:', error))
            }
          } catch (logError) {
            console.warn('‚ö†Ô∏è Erreur logging transcript user:', logError)
          }
          
          // üéØ D√©tection "au revoir" directement depuis OpenAI
          const isGoodbye = userTranscript.toLowerCase().trim().includes('au revoir')
          if (isGoodbye) {
            console.log('üëã [OPENAI USER] AU REVOIR D√âTECT√â dans transcript OpenAI:', userTranscript)
            
            // üöÄ FERMETURE AUTOMATIQUE DE SESSION
            setTimeout(async () => {
              try {
                // Fermer c√¥t√© serveur
                if (sessionRef.current?.session_id) {
                  await fetch('/api/voice/session/close', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ sessionId: sessionRef.current.session_id, reason: 'user_goodbye' }),
                    keepalive: true
                  }).catch(() => {})
                }
                
                // D√©clencher d√©connexion
                await disconnect()
                
                // Notifier le parent (VoiceInterface) pour d√©sactiver
                if (configRef.current.onError) {
                  configRef.current.onError('GOODBYE_DETECTED')
                }
              } catch (error) {
                console.error('‚ùå [OPENAI USER] Erreur fermeture au revoir:', error)
              }
            }, 1000) // D√©lai pour laisser JARVIS r√©pondre "au revoir"
          }
        }
        break

      case 'response.audio_transcript.done':
        console.log('üìù Transcript final:', (event as any).transcript)
        const finalTranscript = ((event as any).transcript as string) || transcriptBufferRef.current
        
        // üîß ACTIVIT√â: Fin de r√©ponse JARVIS = activit√©
        lastActivityRef.current = Date.now()
        
        // üëã D√âTECTION "AU REVOIR" SUPPRIM√âE - g√©r√©e c√¥t√© VoiceInterface pour √©viter conflits
        
        configRef.current.onTranscriptUpdate?.(finalTranscript, true)
        setCurrentTranscript(finalTranscript)
        
        // üìä [TRACKING] Enregistrer la transcription
        if (finalTranscript && sessionTrackingRef.current.sessionId) {
          sessionTrackingRef.current.transcriptHistory.push(`AI: ${finalTranscript}`)
          // Estimer les tokens de sortie (approximation: 1 token ‚âà 4 caract√®res)
          sessionTrackingRef.current.textOutputTokens += Math.ceil(finalTranscript.length / 4)
        }

              // üéôÔ∏è [OPENAI REALTIME] Logging IA int√©gr√© dans le tracking principal
              console.log('ü§ñ [OPENAI REALTIME] IA Response logged:', finalTranscript.substring(0, 50) + '...')
        
        // üéØ [INSTRUMENTATION] Enregistrer la transcription IA finale
        try {
          if (sessionRef.current?.session_id && finalTranscript) {
            // TODO: Prisma recordAudioEvent('response_completed', finalTranscript)
          }
        } catch (error) {
          console.error('‚ùå [INSTRUMENTATION] Erreur response_completed:', error)
        }
        
        transcriptBufferRef.current = ''
        break

      case 'response.audio.done':
        console.log('üîä Audio de r√©ponse termin√©')
        setAudioState(prev => ({ ...prev, isPlaying: false }))
        
        // üìä [TRACKING] Estimer la dur√©e audio de sortie (approximatif)
        if (sessionTrackingRef.current.sessionId) {
          sessionTrackingRef.current.audioOutputSeconds += 3 // Estimation moyenne
        }
        break

      case 'response.done':
        console.log('‚úÖ R√©ponse compl√®te')
        updateStatus('connected')
        break

      case 'error':
        console.error('‚ùå Erreur serveur OpenAI:', event)
        configRef.current.onError?.((event.error as { message?: string })?.message || 'Erreur serveur')
        
        // üìä [TRACKING] Marquer l'erreur
        if (sessionTrackingRef.current.sessionId) {
          sessionTrackingRef.current.errorOccurred = true
        }
        
        updateStatus('error')
        break

      case 'rate_limits.updated':
        console.log('‚ö° Limites de taux mises √† jour:', event.rate_limits)
        break

      default:
        // üîá Logs √©v√©nements non critiques silencieux en production
        if (process.env.NODE_ENV === 'development') {
          console.log('üì® √âv√©nement serveur non g√©r√©:', event.type)
        }
    }
  }, [updateStatus])

  // Fonction principale de connexion
  const connect = useCallback(async () => {
    // üîá Debug logs silencieux en production
    if (process.env.NODE_ENV === 'development') {
      console.log('üî• [CONNECT DEBUG] connect() appel√©e, isConnectingRef.current:', isConnectingRef.current, 'isConnected:', isConnected)
    }
    
    if (isConnectingRef.current || isConnected) {
      console.log('‚ö†Ô∏è Connexion d√©j√† en cours ou √©tablie')
      return
    }

    isConnectingRef.current = true
    updateStatus('connecting')
    console.log('üî• [CONNECT DEBUG] D√©but connexion, appel createSession()')

    try {
      // 1. Cr√©er la session OpenAI avec token eph√©m√®re
      const session = await createSession()
      console.log('üî• [CONNECT DEBUG] createSession() r√©ussie, session:', session)
      
      // 2. Initialiser WebRTC avec la session
      console.log('üî• [CONNECT DEBUG] Appel initializeWebRTC()')
      await initializeWebRTC(session)
      console.log('üî• [CONNECT DEBUG] initializeWebRTC() r√©ussie')
      
      console.log('üöÄ Connexion voice chat √©tablie avec succ√®s')
      
    } catch (error) {
      console.error('Erreur connexion voice chat:', error)
      
      // Messages d'erreur d√©taill√©s selon le type
      let errorMessage = 'Erreur de connexion'
      if (error instanceof Error) {
        if (error.name === 'NotAllowedError') {
          errorMessage = 'Permissions microphone refus√©es. Autorisez le microphone et rechargez la page.'
        } else if (error.name === 'NotFoundError') {
          errorMessage = 'Aucun microphone d√©tect√©. V√©rifiez votre √©quipement audio.'
        } else if (error.name === 'NotReadableError') {
          errorMessage = 'Microphone d√©j√† utilis√© par une autre application.'
        } else if (error.message.includes('Session creation failed')) {
          errorMessage = 'Erreur serveur. Veuillez r√©essayer.'
        } else {
          errorMessage = error.message
        }
      }
      
      configRef.current.onError?.(errorMessage)
      updateStatus('error')
      
      // Tentative de reconnexion automatique (sauf pour les erreurs de permissions)
      if (reconnectAttempts.current < RECONNECT_CONFIG.maxAttempts && 
          !(error instanceof Error && error.name === 'NotAllowedError')) {
        scheduleReconnect()
      }
    } finally {
      isConnectingRef.current = false
    }
  }, [isConnected, createSession, initializeWebRTC, updateStatus, scheduleReconnect])

  // D√©connexion propre (D√âCLAR√âE EN PREMIER pour √©viter erreur hoisting)
  const disconnect = useCallback(async () => {
    console.log('üîå D√âCONNEXION VOICE CHAT - RAISON:', {
      timestamp: new Date().toISOString(),
      isConnected,
      status,
      lastActivity: new Date(lastActivityRef.current).toISOString(),
      timeSinceActivity: Date.now() - lastActivityRef.current,
      sessionId: sessionTrackingRef.current.sessionId
    })
    
    // Nettoyer les timeouts de stabilit√©
    if (stabilityTimeoutRef.current) {
      clearTimeout(stabilityTimeoutRef.current)
      stabilityTimeoutRef.current = null
    }
    
    // Nettoyer les timeouts
    if (reconnectTimeoutRef.current) {
      clearTimeout(reconnectTimeoutRef.current)
      reconnectTimeoutRef.current = null
    }

    // Fermer la peer connection
    if (peerConnectionRef.current) {
      peerConnectionRef.current.close()
      peerConnectionRef.current = null
    }

    // Fermer le data channel
    if (dataChannelRef.current) {
      dataChannelRef.current.close()
      dataChannelRef.current = null
    }

    // Arr√™ter l'audio
    if (audioElementRef.current) {
      audioElementRef.current.srcObject = null
    }

    // üìä [TRACKING] Finaliser le tracking de session AVANT de reset sessionRef
    await finalizeSessionTracking()

    // Reset states
    setIsConnected(false)
    setCurrentTranscript('')
    setAudioState({
      isRecording: false,
      isPlaying: false,
      micPermission: 'prompt',
      audioLevel: 0
    })
    
    sessionRef.current = null
    isConnectingRef.current = false
    reconnectAttempts.current = 0
    transcriptBufferRef.current = ''
    
    updateStatus('idle')
  }, [updateStatus, finalizeSessionTracking])

  // Forcer une reconnexion
  const forceReconnect = useCallback(async () => {
    console.log('üîÑ Reconnexion forc√©e demand√©e')
    await disconnect()
    reconnectAttempts.current = 0
    setTimeout(() => connect(), 1000)
  }, [connect, disconnect])

  // Envoyer un message texte (optionnel)
  const sendTextMessage = useCallback((text: string) => {
    if (!dataChannelRef.current || !isConnected) {
      console.warn('‚ö†Ô∏è Pas de connexion pour envoyer le message')
      return
    }

    const event = {
      type: 'conversation.item.create',
      item: {
        type: 'message',
        role: 'user',
        content: [
          {
            type: 'input_text',
            text: text,
          }
        ]
      }
    }

    dataChannelRef.current.send(JSON.stringify(event))
    
    // D√©clencher une r√©ponse
    const responseEvent = {
      type: 'response.create'
    }
    dataChannelRef.current.send(JSON.stringify(responseEvent))
  }, [isConnected])

  // Nettoyage √† la d√©connexion du composant
  useEffect(() => {
    return () => {
      // Note: cleanup function cannot be async, but disconnect should be called
      disconnect().catch(console.error)
    }
  }, [disconnect])

  return {
    audioState,
    isConnected,
    status,
    currentTranscript,
    connectionQuality,
    reconnectAttempts: reconnectAttempts.current,
    connect,
    disconnect,
    sendTextMessage,
    forceReconnect,
    getCurrentSessionId: () => sessionRef.current?.session_id || null
  }
} 