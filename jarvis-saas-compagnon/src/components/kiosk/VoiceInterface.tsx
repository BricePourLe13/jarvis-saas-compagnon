"use client"
import { useEffect, useState, useCallback, useRef } from 'react'
import { Box, Button, Text, VStack, HStack, Spinner } from '@chakra-ui/react'
import { motion, AnimatePresence } from 'framer-motion'
import { useVoiceChat } from '@/hooks/useVoiceChat'
// import { useGoodbyeDetection } from '@/hooks/useGoodbyeDetection' // ğŸ—‘ï¸ SUPPRIMÃ‰
import AudioVisualizer from './AudioVisualizer'
// import { whisperParallelTracker } from '@/lib/whisper-parallel-tracker' // ğŸ—‘ï¸ SUPPRIMÃ‰
import { kioskLogger } from '@/lib/kiosk-logger'

interface VoiceInterfaceProps {
  gymSlug: string
  currentMember: any
  isActive: boolean
  onActivate: () => void
  onDeactivate: () => void
  onTranscriptUpdate?: (transcript: string, isFinal: boolean) => void
}

export default function VoiceInterface({ 
  gymSlug, 
  currentMember, 
  isActive, 
  onActivate, 
  onDeactivate,
  onTranscriptUpdate 
}: VoiceInterfaceProps) {

  const {
    audioState,
    isConnected,
    status,
    currentTranscript,
    connectionQuality,
    reconnectAttempts,
    connect,
    disconnect,
    sendTextMessage,
    forceReconnect,
    getCurrentSessionId
  } = useVoiceChat({
    gymSlug,
    memberId: currentMember?.id,
    language: currentMember?.member_preferences?.language || 'fr',
    memberData: currentMember ? {
      first_name: currentMember.first_name,
      last_name: currentMember.last_name,
      member_preferences: {
        goals: currentMember.member_preferences?.goals || [],
        favorite_activities: currentMember.member_preferences?.favorite_activities || [],
      },
      last_visit: currentMember.last_visit || '',
      membership_type: currentMember.membership_type,
      total_visits: currentMember.total_visits
    } : undefined,
    onStatusChange: useCallback((newStatus) => {
      console.log('[VOICE UI] Status:', newStatus)
    }, []),
    onTranscriptUpdate: useCallback((text, isFinal) => {
      onTranscriptUpdate?.(text, isFinal)
    }, [onTranscriptUpdate]),
    onError: useCallback((errorMessage) => {
      if (errorMessage === 'GOODBYE_DETECTED') {
        // ğŸ¯ Au revoir dÃ©tectÃ© via OpenAI transcript
        kioskLogger.session('Au revoir dÃ©tectÃ© via OpenAI transcript', 'info')
        onDeactivate() // DÃ©sactiver le membre
      } else {
        console.error('Voice error:', errorMessage)
      }
    }, [onDeactivate])
  })

  // âœ… NOUVEAU: Activation directe du microphone
  useEffect(() => {
    if (isActive && !isConnected && status !== 'connecting' && currentMember) {
      console.log('ğŸ¤ Activation directe du microphone pour:', currentMember.first_name)
      connect()
    }
  }, [isActive, isConnected, status, connect, currentMember])

  useEffect(() => {
    if (!isActive && isConnected) {
      disconnect().catch(console.error)
    }
  }, [isActive, isConnected, disconnect])

  // ğŸ¯ Configurer l'intercepteur quand la connexion est Ã©tablie
  useEffect(() => {
    if (status === 'connected' && currentMember && getCurrentSessionId) {
      const sessionId = getCurrentSessionId()
      if (sessionId) {
        // Configuration du logger avec session
        kioskLogger.setSession(sessionId, currentMember.first_name || 'Membre')
        kioskLogger.session('Connexion WebRTC Ã©tablie', 'success')
        
        // ğŸ™ï¸ [OPENAI REALTIME] Tout est intÃ©grÃ© dans OpenAI maintenant !
        kioskLogger.tracking('Session OpenAI configurÃ©e avec transcripts USER + IA', 'success', { sessionId: sessionId.slice(-6) })
      }
    }
  }, [status, currentMember, getCurrentSessionId])

  // ğŸ¯ DÃ‰TECTION "AU REVOIR" VIA OPENAI TRANSCRIPTS (plus de Speech Recognition)
  const handleGoodbyeDetected = useCallback(async () => {
    kioskLogger.session('Au revoir dÃ©tectÃ© - Fermeture session', 'info')
    try {
      const sessionId = getCurrentSessionId?.()
      if (sessionId) {
        // Fermer cÃ´tÃ© serveur (idempotent)
        await fetch('/api/voice/session/close', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ sessionId, reason: 'user_goodbye' }),
          keepalive: true
        }).catch(() => {})
      }
    } finally {
      // DÃ©connecter et empÃªcher reconnexion automatique
      await disconnect()
    }
    // IMPORTANT: DÃ©sactiver le membre pour empÃªcher reconnexion
    onDeactivate()
  }, [disconnect, onDeactivate, getCurrentSessionId])

  // ğŸ—‘ï¸ SPEECH RECOGNITION SUPPRIMÃ‰ - Detection via OpenAI transcripts maintenant
  
  // ğŸ¯ [OPENAI REALTIME] DÃ©tection "au revoir" via transcripts OpenAI intÃ©grÃ©e dans useVoiceChat

  const getJarvisStatus = () => {
    switch (status) {
      case 'connecting': return 'Connexion...'
      case 'connected': return 'JARVIS vous Ã©coute'
      case 'listening': return 'Je vous Ã©coute...'
      case 'speaking': return 'Je rÃ©ponds...'
      case 'error': return 'Erreur'
      default: return 'Initialisation...'
    }
  }

  if (!isActive) {
    return null
  }

  return (
    <Box position="relative">
      {/* Interface principale */}
      <VStack spacing={4}>
        {isConnected && (
          <HStack spacing={4}>
            <AudioVisualizer 
              isActive={isConnected}
              isListening={status === 'listening'}
              isSpeaking={status === 'speaking'}
              color={status === 'listening' ? '#22c55e' : status === 'speaking' ? '#3b82f6' : '#6366f1'}
              size="sm"
              style="bars"
            />
            <VStack spacing={1} align="start">
              <Text color="white" fontSize="sm">
                Status: {getJarvisStatus()}
              </Text>
              {/* ğŸ¯ [OPENAI REALTIME] DÃ©tection "au revoir" intÃ©grÃ©e */}
              <Text 
                color="green.300" 
                fontSize="xs" 
                display="flex" 
                alignItems="center" 
                gap={1}
              >
                ğŸ¯ DÃ©tection "au revoir" via OpenAI Realtime
              </Text>
            </VStack>
          </HStack>
        )}
        
        {currentTranscript && (
          <Text color="white" fontSize="sm" bg="rgba(0,0,0,0.5)" p={2} borderRadius="md">
            "{currentTranscript}"
          </Text>
        )}
        
        {status === 'connecting' && (
          <VStack spacing={2}>
            <Text color="blue.300" fontSize="sm" textAlign="center">
              ğŸ¤ Connexion Ã  JARVIS...
            </Text>
            <HStack spacing={1}>
              <Spinner size="xs" color="blue.400" />
              <Text color="blue.400" fontSize="xs">
                Initialisation de l'IA
              </Text>
            </HStack>
          </VStack>
        )}
        
        {!isConnected && status !== 'connecting' && status !== 'error' && (
          <Text color="gray.400" fontSize="sm" textAlign="center">
            PrÃªt Ã  se connecter...
          </Text>
        )}
        
        {status === 'error' && (
          <VStack spacing={2}>
            <Text color="red.300" fontSize="sm" textAlign="center">
              âŒ Erreur de connexion audio
            </Text>
            <Button
              size="sm"
              colorScheme="blue"
              onClick={forceReconnect}
            >
              ğŸ”„ RÃ©essayer
            </Button>
          </VStack>
        )}
      </VStack>
    </Box>
  )
} 