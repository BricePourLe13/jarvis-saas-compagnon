# Guide Complet : Agent Vocal GPT Realtime pour Miroir Num√©rique en Salle de Sport

## üìã Table des mati√®res
1. [Vue d'ensemble](#vue-densemble)
2. [Architecture du syst√®me](#architecture-du-syst√®me)
3. [Configuration de l'API](#configuration-de-lapi)
4. [Impl√©mentation pratique](#impl√©mentation-pratique)
5. [Gestion de l'audio](#gestion-de-laudio)
6. [D√©ploiement](#d√©ploiement)
7. [Bonnes pratiques](#bonnes-pratiques)

---

## Vue d'ensemble

### Mod√®le √† utiliser
- **Mod√®le**: `gpt-realtime` (derni√®re version GA - Ao√ªt 2025)
- **Type de connexion**: WebSocket ou WebRTC
- **Latence**: Sub-seconde (< 1s)
- **Format audio**: PCM16 √† 24 kHz ou 16 kHz

### Avantages du gpt-realtime
- **Pr√©cision accrue**: 66.5% accuracy en function calling (vs 49.7% avant)
- **Naturalit√© vocale**: Meilleure expressivit√© et intonation
- **Nouvelles voix**: Cedar et Marin (exclusives)
- **Prix optimis√©**: 20% moins cher que la version pr√©c√©dente
- **Appels asynchrones**: Les fonctions longues n'interrompent pas la conversation

---

## Architecture du syst√®me

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         MIROIR NUM√âRIQUE (Frontend)             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ Microphone    ‚îÇ          ‚îÇ  Haut-parleurs ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ (Capture)    ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  (Playback)    ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ
                   ‚îÇ WebSocket (WSS)
                   ‚îÇ Audio PCM 16-bit
                   ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ        OPENAI REALTIME API (Backend)            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  gpt-realtime Model                      ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Speech-to-Speech                      ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Function Calling                      ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Multi-language Support                ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ
                   ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ        SERVICES BACKEND (Optionnel)             ‚îÇ
‚îÇ  - Authentification adh√©rents                   ‚îÇ
‚îÇ  - Donn√©es de fitness                           ‚îÇ
‚îÇ  - Historique d'entra√Ænement                    ‚îÇ
‚îÇ  - Int√©grations MCP                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Configuration de l'API

### 1. Authentication & Connexion

#### Option A: WebSocket Direct (Serveur)
```javascript
const OPENAI_API_KEY = process.env.OPENAI_API_KEY;
const MODEL = "gpt-realtime";

const url = `wss://api.openai.com/v1/realtime?model=${MODEL}`;

const ws = new WebSocket(url, {
  headers: {
    "Authorization": `Bearer ${OPENAI_API_KEY}`,
    "OpenAI-Beta": "realtime=v1",
  },
});

ws.on("open", () => {
  console.log("‚úÖ Connect√© √† OpenAI Realtime API");
});
```

#### Option B: Ephemeral Token (Client)
Pour une utilisation directe dans le miroir sans exposer la cl√© API:

```javascript
// Sur le serveur backend
app.post("/session", async (req, res) => {
  const response = await fetch("https://api.openai.com/v1/realtime/sessions", {
    method: "POST",
    headers: {
      "Authorization": `Bearer ${OPENAI_API_KEY}`,
      "Content-Type": "application/json",
    },
    body: JSON.stringify({ model: "gpt-realtime" }),
  });
  
  const data = await response.json();
  res.json({
    client_secret: data.client_secret.value, // 1 min expiration
  });
});

// Dans le miroir (frontend)
const sessionData = await fetch("/session").then(r => r.json());
const ws = new WebSocket(
  `wss://api.openai.com/v1/realtime?model=gpt-realtime`,
  [
    "realtime",
    `openai-insecure-api-key.${sessionData.client_secret}`
  ]
);
```

### 2. Configuration de Session

La **configuration critique** pour votre cas d'usage (salle de sport):

```json
{
  "type": "session.update",
  "session": {
    "type": "realtime",
    "instructions": "Tu es un assistant vocal pour une salle de sport. Tu aides les adh√©rents avec leurs questions sur les √©quipements, les cours, les horaires. R√©ponds en fran√ßais, sois amical et enthousiaste. Garde tes r√©ponses concises (< 30 secondes de parole).",
    "voice": "cedar",
    "output_modalities": ["audio"],
    "audio": {
      "input": {
        "format": {
          "type": "audio/pcm",
          "rate": 24000
        },
        "transcription": {
          "model": "whisper-1"
        },
        "turn_detection": {
          "type": "server_vad",
          "threshold": 0.5,
          "prefix_padding_ms": 300,
          "silence_duration_ms": 500,
          "create_response": true
        }
      },
      "output": {
        "voice": "cedar",
        "format": {
          "type": "audio/pcm",
          "rate": 24000
        }
      }
    }
  }
}
```

#### Param√®tres cl√©s expliqu√©s
| Param√®tre | Valeur | Explication |
|-----------|--------|-------------|
| `voice` | cedar/marin | Voix pour les r√©ponses (cedar meilleur pour FR) |
| `threshold` | 0.5 | Sensibilit√© VAD (0-1: 0.5 = √©quilibre bruit/sensibilit√©) |
| `silence_duration_ms` | 500 | Temps de silence avant fin de tour |
| `prefix_padding_ms` | 300 | Padding audio avant d√©tection (< latence) |
| `rate` | 24000 Hz | Qualit√© audio (24kHz meilleur que 16kHz) |

---

## Impl√©mentation pratique

### Architecture TypeScript/JavaScript

```typescript
import WebSocket from "ws";

interface RealtimeSession {
  instructions: string;
  voice: "cedar" | "marin";
  modalities: string[];
  audio: {
    input: { format: { type: string; rate: number } };
    output: { voice: string; format: { type: string; rate: number } };
  };
}

class VoiceAgentMirror {
  private ws: WebSocket;
  private audioQueue: Uint8Array[] = [];
  private audioContext: AudioContext;
  private mediaRecorder: MediaRecorder;

  async initialize() {
    // 1. Connexion WebSocket
    const sessionToken = await this.getEphemeralToken();
    this.ws = new WebSocket(
      `wss://api.openai.com/v1/realtime?model=gpt-realtime`,
      ["realtime", `openai-insecure-api-key.${sessionToken}`]
    );

    this.ws.onopen = () => this.setupSession();
    this.ws.onmessage = (event) => this.handleServerEvent(JSON.parse(event.data));
    this.ws.onerror = (error) => console.error("WebSocket error:", error);

    // 2. Configuration audio
    this.audioContext = new AudioContext({ sampleRate: 24000 });
    await this.audioContext.resume();

    // 3. Capture microphone
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    this.startAudioCapture(stream);
  }

  private setupSession() {
    const sessionConfig = {
      type: "session.update",
      session: {
        type: "realtime",
        instructions: "Tu es un assistant vocal pour une salle de sport...",
        voice: "cedar",
        output_modalities: ["audio"],
        audio: {
          input: {
            format: { type: "audio/pcm", rate: 24000 },
            transcription: { model: "whisper-1" },
            turn_detection: {
              type: "server_vad",
              threshold: 0.5,
              prefix_padding_ms: 300,
              silence_duration_ms: 500,
              create_response: true,
            },
          },
          output: {
            voice: "cedar",
            format: { type: "audio/pcm", rate: 24000 },
          },
        },
      },
    };

    this.ws.send(JSON.stringify(sessionConfig));
  }

  private startAudioCapture(stream: MediaStream) {
    const processor = this.audioContext.createScriptProcessor(4096, 1, 1);
    const source = this.audioContext.createMediaStreamSource(stream);
    source.connect(processor);
    processor.connect(this.audioContext.destination);

    processor.onaudioprocess = (event) => {
      const audioData = event.inputBuffer.getChannelData(0);
      const pcm16 = this.float32ToPCM16(audioData);
      const base64Audio = this.arrayBufferToBase64(pcm16);

      // Envoyer √† OpenAI
      this.ws.send(
        JSON.stringify({
          type: "input_audio_buffer.append",
          audio: base64Audio,
        })
      );
    };
  }

  private handleServerEvent(event: any) {
    switch (event.type) {
      case "session.created":
        console.log("‚úÖ Session cr√©√©e:", event.session.id);
        break;

      case "response.output_audio.delta":
        // Audio de r√©ponse √† jouer
        const audioData = Buffer.from(event.delta, "base64");
        this.playAudio(audioData);
        break;

      case "response.output_audio_transcript.delta":
        console.log("üìù R√©ponse:", event.delta);
        break;

      case "response.done":
        console.log("‚úÖ R√©ponse compl√®te");
        break;

      case "input_audio_buffer.speech_started":
        console.log("üé§ Utilisateur commence √† parler");
        break;

      case "error":
        console.error("‚ùå Erreur API:", event.error);
        break;
    }
  }

  private async playAudio(audioBuffer: ArrayBuffer) {
    const audioBuffer_web = this.audioContext.createBuffer(
      1,
      audioBuffer.byteLength / 2,
      24000
    );
    const channelData = audioBuffer_web.getChannelData(0);
    const view = new Int16Array(audioBuffer);

    for (let i = 0; i < view.length; i++) {
      channelData[i] = view[i] / 32768.0;
    }

    const source = this.audioContext.createBufferSource();
    source.buffer = audioBuffer_web;
    source.connect(this.audioContext.destination);
    source.start(0);
  }

  private float32ToPCM16(float32Array: Float32Array): Int16Array {
    const pcm16 = new Int16Array(float32Array.length);
    for (let i = 0; i < float32Array.length; i++) {
      pcm16[i] = Math.max(-1, Math.min(1, float32Array[i])) * 0x7fff;
    }
    return pcm16;
  }

  private arrayBufferToBase64(buffer: Int16Array): string {
    const bytes = new Uint8Array(buffer.buffer);
    let binary = "";
    for (let i = 0; i < bytes.byteLength; i++) {
      binary += String.fromCharCode(bytes[i]);
    }
    return btoa(binary);
  }

  private async getEphemeralToken(): Promise<string> {
    const response = await fetch("/api/session", { method: "POST" });
    const data = await response.json();
    return data.client_secret;
  }
}

// Utilisation
const mirror = new VoiceAgentMirror();
await mirror.initialize();
```

### Implementation Python (Agents SDK)

```python
import asyncio
from agents.realtime import RealtimeAgent, RealtimeRunner

async def main():
    # Cr√©er l'agent
    agent = RealtimeAgent(
        name="Assistant Fitness",
        instructions="""Tu es un assistant vocal pour une salle de sport.
Tu aides les adh√©rents avec:
- Informations sur les √©quipements
- Horaires des cours
- Conseils fitness
- R√©servations de cours

R√©ponds toujours en fran√ßais, sois amical et enthousiaste.
Garde tes r√©ponses courtes (< 30 secondes de parole).""",
    )

    # Configuration runner
    runner = RealtimeRunner(
        starting_agent=agent,
        config={
            "model_settings": {
                "model_name": "gpt-realtime",
                "voice": "cedar",
                "modalities": ["audio"],
                "input_audio_format": "pcm16",
                "output_audio_format": "pcm16",
                "input_audio_transcription": {"model": "whisper-1"},
                "turn_detection": {
                    "type": "server_vad",
                    "threshold": 0.5,
                    "silence_duration_ms": 500,
                    "prefix_padding_ms": 300,
                },
            }
        },
    )

    # D√©marrer session
    session = await runner.run()
    async with session:
        print("üé§ Agent vocal pr√™t - Miroir de fitness actif")
        async for event in session:
            if event.type == "agent_start":
                print(f"‚úÖ {event.agent.name} a d√©marr√©")
            elif event.type == "audio_end":
                print("‚úÖ R√©ponse vocale termin√©e")
            elif event.type == "error":
                print(f"‚ùå Erreur: {event.error}")

if __name__ == "__main__":
    asyncio.run(main())
```

---

## Gestion de l'audio

### Format audio recommand√©
- **PCM16** (16-bit signed little-endian)
- **24 kHz** (qualit√© sup√©rieure, recommand√©)
- **Mono** (1 channel)
- **Buffer size**: 4096 samples ‚âà 170ms

### Pipeline audio compl√®te

```
Microphone
    ‚Üì
[Audio Worklet / ScriptProcessor]
    ‚Üì
Float32 ‚Üí PCM16 Conversion
    ‚Üì
Base64 Encoding
    ‚Üì
WebSocket Send
    ‚Üì
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    ‚Üì
WebSocket Receive (base64 audio)
    ‚Üì
Base64 Decoding
    ‚Üì
PCM16 ‚Üí Float32 Conversion
    ‚Üì
Audio Buffer Creation
    ‚Üì
Audio Context Play
    ‚Üì
Haut-parleurs
```

### Optimisation latence pour miroir
```javascript
// ‚ö†Ô∏è CRITIQUE: Timing pour salle de sport
const AUDIO_CHUNK_SIZE = 2048; // ~85ms @ 24kHz (compromis)
const VAD_SILENCE_MS = 500; // D√©tecte fin de phrase
const VAD_THRESHOLD = 0.4; // Moins sensible au bruit ambiant

// Configuration agressive pour environnement bruyant
{
  "turn_detection": {
    "type": "server_vad",
    "threshold": 0.4,  // < bruit ambiant
    "silence_duration_ms": 500,  // > pause naturelle
    "prefix_padding_ms": 300,
    "create_response": true,
    "interrupt_response": true  // Interrupte si l'user parle
  }
}
```

---

## D√©ploiement

### Architecture recommand√©e

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ        Miroir Num√©rique (Kiosk)             ‚îÇ
‚îÇ  - √âcran tactile 24"                        ‚îÇ
‚îÇ  - Raspberry Pi 5 / Mini PC                 ‚îÇ
‚îÇ  - Microphone + Haut-parleurs               ‚îÇ
‚îÇ  - Electron App (TypeScript/React)          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ WiFi/Ethernet
              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ    Serveur Backend (VPS/Cloud)              ‚îÇ
‚îÇ  - Node.js Express                          ‚îÇ
‚îÇ  - Token ephemeral generation               ‚îÇ
‚îÇ  - Authentification adh√©rents               ‚îÇ
‚îÇ  - Logging & Monitoring                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ HTTPS
              ‚ñº
        OpenAI API (wss://)
```

### Variables d'environnement
```bash
OPENAI_API_KEY=sk-...
OPENAI_ORG_ID=org-... (optionnel)
MIRROR_LOCATION=gym-paris-main-floor
API_BACKEND_URL=https://api.gym.local
LOG_LEVEL=info
SESSION_TIMEOUT=3600
```

### Docker Compose (Backend)
```yaml
version: '3.8'
services:
  backend:
    image: node:18-alpine
    environment:
      OPENAI_API_KEY: ${OPENAI_API_KEY}
    ports:
      - "3000:3000"
    volumes:
      - ./src:/app/src
    command: npm start

  nginx:
    image: nginx:alpine
    ports:
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./certs:/etc/nginx/certs
```

---

## Bonnes pratiques

### 1. Gestion des erreurs
```javascript
ws.on("error", (error) => {
  console.error("‚ùå Erreur WebSocket:", error);
  // Reconnecter apr√®s 5 secondes
  setTimeout(() => mirror.reconnect(), 5000);
});

// Timeout de session (60 min max par API)
setTimeout(() => {
  ws.close();
  mirror.initialize(); // Nouvelle session
}, 60 * 60 * 1000);
```

### 2. Contr√¥le du volume/Feedback utilisateur
```javascript
// Afficher sur l'√©cran du miroir pendant la r√©ponse
{
  "type": "response.output_audio_transcript.delta",
  "transcript": "Je vous recommande les halt√®res..."
}
// ‚Üí Afficher le texte en temps r√©el sous-titrage

// Indicateurs visuels
- Pulsation rouge: microphone actif
- Onde verte: r√©ponse en cours
- Coche bleue: r√©ponse re√ßue
```

### 3. Multilangue (salle internationale)
```javascript
// D√©tecter la langue et adapter
const systemPrompt = language === "fr" 
  ? "Tu es un assistant fran√ßais..."
  : language === "es"
  ? "Eres un asistente espa√±ol..."
  : "You are an English assistant...";
```

### 4. Security
```javascript
// ‚úÖ DO: Token √©ph√©m√®re (1 min expiration)
const ephemeralToken = await getEphemeralToken(); // Backend route

// ‚ùå DON'T: Cl√© API expos√©e en frontend
// const ws = new WebSocket(..., ["openai-insecure-api-key.sk-..."])

// Valider entr√©es utilisateur
if (userInput.length > 500) {
  console.warn("‚ùå Input trop long - possible injection");
}
```

### 5. Monitoring & Analytics
```javascript
const metrics = {
  sessionStart: Date.now(),
  messagesCount: 0,
  totalDuration: 0,
  errors: [],
};

// Logger pour chaque interaction
console.log({
  timestamp: new Date().toISOString(),
  location: "gym-paris-main",
  userQuery: event.transcript,
  responseTime: Date.now() - startTime,
  confidence: event.confidence,
});
```

### 6. Optimisation co√ªt
```javascript
// Pricing (Nov 2025): $32/1M input + $64/1M output tokens (audio)
// = ~$0.003 par minute pour 50 utilisateurs/jour

// R√©duire co√ªts:
// 1. Compression audio (G.711)
// 2. Cache de r√©ponses fr√©quentes
// 3. Batch processing off-peak
// 4. Cleanup sessions toutes les heures
```

---

## Resources utiles

- **Doc officielle**: https://platform.openai.com/docs/guides/realtime
- **Agents SDK**: https://github.com/openai/openai-agents-sdk
- **Migration Beta‚ÜíGA**: https://platform.openai.com/docs/guides/realtime#beta-to-ga-migration
- **Exemples GitHub**: https://github.com/openai/openai-realtime-agents
- **Community**: Discord OpenAI Developers

---

## Prochaines √©tapes

1. ‚úÖ Tester connexion WebSocket avec curl
2. ‚úÖ Capturer audio microphone et l'encoder PCM16
3. ‚úÖ Impl√©menter boucle √©v√©nementielle compl√®te
4. ‚úÖ Tester avec phrases courtes (< 5s)
5. ‚úÖ D√©ployer sur miroir de test
6. ‚úÖ Calibrer param√®tres VAD pour bruit ambiant
7. ‚úÖ Int√©grer base de donn√©es adh√©rents
8. ‚úÖ Ajouter tracking analytics
