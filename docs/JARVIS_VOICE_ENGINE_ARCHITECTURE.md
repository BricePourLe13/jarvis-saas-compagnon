# üéôÔ∏è JARVIS VOICE ENGINE - Architecture Technique

> **‚ö†Ô∏è DOCUMENT OBSOL√àTE - Voir JARVIS_VOICE_ENGINE_ARCHITECTURE_V3.md**  
> **Version :** 1.0.0 (Architecture V2 - Kyutai Unmute + CrewAI)  
> **Date :** 17 octobre 2025  
> **Auteur :** Brice PRADET - JARVIS-GROUP  
> **Status :** ‚ùå REMPLAC√â par V3.0 (Groq + Chatterbox + Analytics MVP)

---

## üìã Table des mati√®res

1. [Vue d'ensemble](#vue-densemble)
2. [Contexte et motivation](#contexte-et-motivation)
3. [Architecture syst√®me](#architecture-syst√®me)
4. [Stack technologique](#stack-technologique)
5. [Composants d√©taill√©s](#composants-d√©taill√©s)
6. [Flux de donn√©es](#flux-de-donn√©es)
7. [D√©ploiement RunPod](#d√©ploiement-runpod)
8. [Migration depuis OpenAI](#migration-depuis-openai)
9. [S√©curit√© et performance](#s√©curit√©-et-performance)
10. [Co√ªts et scalabilit√©](#co√ªts-et-scalabilit√©)
11. [Plan de d√©ploiement](#plan-de-d√©ploiement)

---

## üéØ Vue d'ensemble

### Objectif

Cr√©er un **moteur vocal IA open-source** auto-h√©berg√© capable de :
- ‚úÖ Conversations speech-to-speech en temps r√©el (< 500ms latence)
- ‚úÖ Voix fran√ßaise naturelle et humaine
- ‚úÖ Ex√©cution de tools/actions (MCP protocol)
- ‚úÖ Chargement de contexte personnalis√© (profil adh√©rent, salle, m√©t√©o)
- ‚úÖ Multi-tenant (plusieurs salles de sport)
- ‚úÖ Scalable et commercialisable

### Principe

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         JARVIS VOICE ENGINE                              ‚îÇ
‚îÇ                    (Self-hosted sur RunPod A10 24GB)                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                    ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ               ‚îÇ               ‚îÇ
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ   Kiosque 1  ‚îÇ ‚îÇ Kiosque 2  ‚îÇ ‚îÇ Kiosque N  ‚îÇ
            ‚îÇ  (Salle A)   ‚îÇ ‚îÇ (Salle B)  ‚îÇ ‚îÇ (Salle N)  ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìå Contexte et motivation

### Limites actuelles (OpenAI Realtime API)

| Probl√®me | Impact |
|----------|--------|
| **Co√ªt √©lev√©** | $0.06/min input + $0.24/min output = **~$18/h** par kiosque |
| **Vendor lock-in** | D√©pendance totale √† OpenAI |
| **Pas de contr√¥le** | Impossible de customiser voix, latence, comportement |
| **Limite scalabilit√©** | 100 sessions simultan√©es max |
| **Pas commercialisable** | On ne peut pas revendre la solution facilement |

### Objectifs de la migration

| Objectif | R√©sultat attendu |
|----------|------------------|
| **R√©duire co√ªts** | **< $2/h** par instance (au lieu de $18/h) |
| **Ind√©pendance** | Stack 100% open-source, pas de vendor lock-in |
| **Performance** | Latence < 500ms (vs ~800ms OpenAI) |
| **Customisation** | Voix fran√ßaise premium, outils sur mesure |
| **Scalabilit√©** | Illimit√©e (horizontal scaling) |
| **Commercialisation** | Solution white-label vendable √† d'autres secteurs |

---

## üèóÔ∏è Architecture syst√®me

### Sch√©ma global (bas√© sur Kyutai Unmute)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                            FRONTEND (Next.js)                                 ‚îÇ
‚îÇ                    Vercel - jarvis-group.net                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ  Landing Page   ‚îÇ  ‚îÇ  Dashboard Admin ‚îÇ  ‚îÇ  Kiosk Interface (TS)   ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                    ‚îÇ
                         WebSocket (Audio Stream)
                                    ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  JARVIS VOICE ENGINE (RunPod A10 24GB)                        ‚îÇ
‚îÇ                    Bas√© sur Kyutai Unmute + Extensions                        ‚îÇ
‚îÇ                                                                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ                    UNMUTE BACKEND (FastAPI)                            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                         Port 8000                                      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                                         ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ              JARVIS EXTENSIONS (Custom)                          ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚Ä¢ Context Loader (membre, salle, m√©t√©o)                        ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚Ä¢ MCP Tools Integration                                        ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚Ä¢ Multi-tenant routing                                         ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚Ä¢ Supabase connector                                           ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚Ä¢ Session logging                                              ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ  Kyutai STT ‚îÇ‚Üí ‚îÇ     LLM      ‚îÇ‚Üí ‚îÇ  Kyutai TTS  ‚îÇ  ‚îÇ     Redis     ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ   (2.5GB)   ‚îÇ  ‚îÇ VLLM/Groq    ‚îÇ  ‚îÇ   (5.3GB)    ‚îÇ  ‚îÇ   (Cache)     ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ             ‚îÇ  ‚îÇ   (6.1GB)    ‚îÇ  ‚îÇ              ‚îÇ  ‚îÇ               ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                                                                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ                    MCP TOOLS SERVER (Port 8001)                        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                                         ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ get_member_profile()      ‚Ä¢ display_video_tutorial()              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ log_interaction()         ‚Ä¢ contact_coach()                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ get_gym_info()            ‚Ä¢ book_session()                        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ detect_churn_risk()       ‚Ä¢ create_mission()                      ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                                               ‚îÇ
‚îÇ  Total VRAM: ~14GB / 24GB                                                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                    ‚îÇ
                            HTTPS REST API
                                    ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         SUPABASE (Backend)                                    ‚îÇ
‚îÇ                    PostgreSQL + Auth + Storage                                ‚îÇ
‚îÇ                                                                               ‚îÇ
‚îÇ  ‚Ä¢ gym_members (profils adh√©rents)                                           ‚îÇ
‚îÇ  ‚Ä¢ gyms (profils salles)                                                     ‚îÇ
‚îÇ  ‚Ä¢ voice_sessions (historique conversations)                                 ‚îÇ
‚îÇ  ‚Ä¢ jarvis_interactions (logs d√©taill√©s)                                      ‚îÇ
‚îÇ  ‚Ä¢ missions (t√¢ches cr√©√©es par g√©rants)                                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üõ†Ô∏è Stack technologique

### Infrastructure

| Composant | Technologie | Justification |
|-----------|-------------|---------------|
| **Hosting GPU** | RunPod A10 24GB | Meilleur rapport perf/prix ($0.39/h) |
| **D√©ploiement** | Dockerless (systemd) | Pas de Docker-in-Docker, natif RunPod |
| **Communication** | WebSocket | Compatible OpenAI Realtime API |
| **Cache** | Redis | Ultra-rapide pour sessions |
| **Backend** | Supabase PostgreSQL | Existant, pas de changement |

### IA & Voice (Kyutai Unmute)

| Composant | Technologie | Justification |
|-----------|-------------|---------------|
| **Base** | **Kyutai Unmute** | Solution compl√®te, production-ready, ~450ms latence |
| **STT** | Kyutai Speech-to-Text | Optimis√© low-latency, 2.5GB VRAM |
| **LLM** | VLLM (Mistral 24B) ou Groq | VLLM local 6.1GB VRAM, ou Groq API externe |
| **TTS** | Kyutai Text-to-Speech | Voix fran√ßaise premium, 5.3GB VRAM |
| **VAD** | Int√©gr√© dans Kyutai STT | D√©tection vocale temps r√©el |
| **Orchestration** | FastAPI (Unmute Backend) | D√©j√† cod√©, test√© en prod |

### Backend & API

| Composant | Technologie | Justification |
|-----------|-------------|---------------|
| **API** | FastAPI (Unmute) | Async natif, WebSocket, test√© en prod |
| **Extensions** | JARVIS Custom Modules | Context loader, MCP integration |
| **Tools Protocol** | MCP (Model Context Protocol) | Standard √©mergent pour tools IA |
| **Monitoring** | Logs + Supabase | Simple et efficace |

---

## üîß Composants d√©taill√©s

### 1. Unmute Backend (base)

**R√¥le :** Pipeline vocal complet STT ‚Üí LLM ‚Üí TTS

**Ce qu'Unmute fournit d√©j√† :**
- ‚úÖ WebSocket server (compatible OpenAI Realtime API)
- ‚úÖ Kyutai STT optimis√© (2.5GB VRAM, latence ~150ms)
- ‚úÖ Kyutai TTS fran√ßais premium (5.3GB VRAM, latence ~200ms)
- ‚úÖ Int√©gration VLLM pour LLM local
- ‚úÖ VAD (Voice Activity Detection)
- ‚úÖ Gestion des sessions
- ‚úÖ Pipeline audio optimis√©

**Documentation Unmute :** https://github.com/kyutai-labs/unmute

---

### 2. JARVIS Extensions (√† d√©velopper)

**R√¥le :** Adapter Unmute pour les besoins sp√©cifiques de JARVIS

**Modules √† cr√©er :**

#### **A. Context Loader**

Charge tout le contexte n√©cessaire depuis Supabase :

```python
# unmute/jarvis_extensions/context_loader.py
from supabase import create_client
import httpx

supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

async def load_member_context(badge_id: str, gym_slug: str) -> Dict:
    """
    Charge contexte complet pour personnaliser la conversation
    """
    # 1. Profil membre
    member = await supabase.from('gym_members')\
        .select('*')\
        .eq('badge_id', badge_id)\
        .eq('is_active', True)\
        .single()
    
    # 2. Profil salle
    gym = await supabase.from('gyms')\
        .select('*')\
        .eq('slug', gym_slug)\
        .single()
    
    # 3. Historique conversations (5 derni√®res)
    history = await supabase.from('voice_sessions')\
        .select('summary, sentiment, created_at')\
        .eq('member_id', member['id'])\
        .order('created_at', desc=True)\
        .limit(5)
    
    # 4. M√©t√©o locale
    weather = await get_weather(gym['location'])
    
    # 5. Coach pr√©f√©r√©
    coach = await supabase.from('gym_staff')\
        .select('first_name, speciality')\
        .eq('id', member['preferred_coach_id'])\
        .single()
    
    return {
        'member': member,
        'gym': gym,
        'history': history,
        'weather': weather,
        'coach': coach,
        'datetime': datetime.now().isoformat(),
    }

async def get_weather(location: str) -> Dict:
    """R√©cup√®re m√©t√©o via API externe"""
    response = await httpx.get(f'https://api.openweathermap.org/data/2.5/weather?q={location}')
    return response.json()
```

#### **B. System Prompt Generator**

G√©n√®re des prompts personnalis√©s :

```python
# unmute/jarvis_extensions/prompt_generator.py

def generate_jarvis_prompt(context: Dict) -> str:
    """
    G√©n√®re system prompt ultra-personnalis√©
    """
    member = context['member']
    gym = context['gym']
    weather = context['weather']
    coach = context.get('coach')
    
    prompt = f"""Tu es JARVIS, l'assistant vocal intelligent de {gym['name']}.

**PROFIL ADH√âRENT**
- Pr√©nom : {member['first_name']}
- √Çge : {member['age']} ans
- Objectif : {member['goal']}
- Niveau : {member['experience_level']}
- Derni√®re visite : {member['last_visit']}
- Fr√©quence : {member['visit_frequency']}/semaine

**CONTEXTE ACTUEL**
- Date : {context['datetime']}
- M√©t√©o : {weather['description']} ({weather['temp']}¬∞C)
- Coach pr√©f√©r√© : {coach['first_name']} ({coach['speciality']})

**HISTORIQUE R√âCENT**
{format_history(context['history'])}

**TES R√àGLES D'OR**
1. R√©ponds de fa√ßon ultra-naturelle et conversationnelle
2. Sois empathique et encourageant
3. Ne remplace JAMAIS un coach pour conseils avanc√©s
4. Utilise les tools disponibles pour aider concr√®tement
5. Si tu d√©tectes de la frustration/d√©motivation ‚Üí PRIORIT√â ABSOLUE : pr√©venir le churn

**TOOLS DISPONIBLES**
- display_video_tutorial(exercise_name) : afficher vid√©o tuto
- contact_coach(message) : appeler un coach
- book_session(datetime) : r√©server s√©ance coaching
- log_churn_risk(reason) : signaler risque de churn au g√©rant

Parle fran√ßais naturel, tutoie, sois chaleureux mais professionnel.
"""
    return prompt
```

#### **C. MCP Tools Integration**

Int√®gre les outils JARVIS dans Unmute :

```python
# unmute/jarvis_extensions/tools_integration.py

async def register_jarvis_tools(unmute_backend):
    """
    Enregistre tous les tools JARVIS dans Unmute
    """
    tools = [
        {
            "type": "function",
            "name": "display_video_tutorial",
            "description": "Affiche une vid√©o tutoriel d'exercice sur l'√©cran du kiosque",
            "parameters": {
                "type": "object",
                "properties": {
                    "exercise_name": {
                        "type": "string",
                        "description": "Nom de l'exercice (ex: 'developpe-couche', 'squat')"
                    }
                },
                "required": ["exercise_name"]
            }
        },
        {
            "type": "function",
            "name": "contact_coach",
            "description": "Contacter un coach disponible pour assistance",
            "parameters": {
                "type": "object",
                "properties": {
                    "message": {
                        "type": "string",
                        "description": "Message pour le coach"
                    },
                    "urgency": {
                        "type": "string",
                        "enum": ["low", "medium", "high"],
                        "default": "medium"
                    }
                },
                "required": ["message"]
            }
        },
        {
            "type": "function",
            "name": "log_churn_risk",
            "description": "Signaler un risque de churn d√©tect√© au g√©rant",
            "parameters": {
                "type": "object",
                "properties": {
                    "reason": {
                        "type": "string",
                        "description": "Raison du risque (frustration, mat√©riel HS, etc.)"
                    },
                    "severity": {
                        "type": "string",
                        "enum": ["low", "medium", "high", "critical"]
                    }
                },
                "required": ["reason", "severity"]
            }
        }
    ]
    
    unmute_backend.register_tools(tools, execute_jarvis_tool)

async def execute_jarvis_tool(tool_name: str, args: Dict) -> Dict:
    """
    Ex√©cute un tool JARVIS
    """
    # Appel au MCP Tools Server
    response = await httpx.post(
        f'http://localhost:8001/tools/{tool_name}',
        json=args,
        timeout=5.0
    )
    
    # Log dans Supabase
    await supabase.from('jarvis_interactions').insert({
        'session_id': current_session_id,
        'tool_name': tool_name,
        'args': args,
        'result': response.json(),
        'created_at': datetime.now().isoformat()
    })
    
    return response.json()
```

---

### 3. MCP Tools Server

**R√¥le :** Ex√©cuter les actions demand√©es par l'agent vocal

**Architecture :**
```typescript
// mcp-tools-server/src/index.ts
import { Server } from "@modelcontextprotocol/sdk/server/index.js";

const tools = [
  {
    name: "get_member_profile",
    description: "R√©cup√©rer le profil complet d'un adh√©rent",
    parameters: { member_id: "string" },
    handler: async ({ member_id }) => {
      const { data } = await supabase
        .from("gym_members")
        .select("*")
        .eq("id", member_id)
        .single();
      return data;
    },
  },
  {
    name: "display_video_tutorial",
    description: "Afficher une vid√©o tuto d'exercice sur l'√©cran",
    parameters: { exercise_name: "string" },
    handler: async ({ exercise_name }) => {
      // Envoyer √©v√©nement WebSocket au kiosk
      await websocket.send({
        type: "display_video",
        url: `/videos/${exercise_name}.mp4`,
      });
      return { success: true };
    },
  },
  {
    name: "contact_coach",
    description: "Contacter un coach disponible",
    parameters: { coach_id: "string", message: "string" },
    handler: async ({ coach_id, message }) => {
      // Envoyer notification push au coach
      await sendPushNotification(coach_id, message);
      return { success: true, eta: "5 minutes" };
    },
  },
  // ... autres tools
];
```

**Liste compl√®te des tools :**

| Tool | Description | Param√®tres |
|------|-------------|------------|
| `get_member_profile` | Profil adh√©rent | member_id |
| `log_interaction` | Logger conversation | session_id, summary, sentiment |
| `get_gym_info` | Infos salle | gym_slug |
| `display_video_tutorial` | Afficher vid√©o | exercise_name |
| `contact_coach` | Appeler coach | coach_id, message |
| `book_session` | R√©server s√©ance | member_id, coach_id, datetime |
| `detect_churn_risk` | Analyser risque churn | member_id, interaction_data |
| `create_mission` | Cr√©er mission g√©rant | gym_slug, title, description |
| `get_weather` | M√©t√©o actuelle | location |
| `get_member_stats` | Stats entra√Ænement | member_id |

---

### 7. Redis Cache

**R√¥le :** Cache ultra-rapide pour sessions et contexte

**Donn√©es stock√©es :**

```redis
# Session state
SET session:{session_id}:state '{
  "member_id": "...",
  "gym_slug": "...",
  "started_at": "...",
  "context": {...},
  "conversation_history": [...]
}'
EXPIRE session:{session_id}:state 3600

# Member context cache
SET member:{member_id}:context '{...}'
EXPIRE member:{member_id}:context 300

# Rate limiting
INCR ratelimit:{gym_slug}:{hour}
EXPIRE ratelimit:{gym_slug}:{hour} 3600
```

---

## üîÑ Flux de donn√©es

### Sc√©nario complet : "Adh√©rent demande conseil exercice"

```mermaid
sequenceDiagram
    participant K as Kiosk (Browser)
    participant L as LiveKit
    participant O as Orchestrator
    participant S as STT (Whisper)
    participant LLM as Groq LLM
    participant M as MCP Tools
    participant TTS as Kokoro TTS
    participant DB as Supabase

    K->>K: User scanne badge
    K->>O: POST /session/create {badge_id, gym_slug}
    O->>DB: Fetch member profile
    DB-->>O: {member_data}
    O->>O: Load context (profil, m√©t√©o, heure)
    O-->>K: {session_id, livekit_token}
    
    K->>L: Connect WebRTC room
    L-->>K: Connected
    
    K->>L: Stream audio (user speaks)
    L->>O: Audio chunks
    O->>S: Transcribe audio
    S-->>O: "Comment faire du d√©velopp√© couch√© ?"
    
    O->>LLM: Reasoning + Tools
    LLM-->>O: {tool_call: "display_video_tutorial", args: {exercise: "developpe-couche"}}
    
    O->>M: Execute tool
    M->>K: WebSocket event {type: "video", url: "..."}
    K->>K: Display video overlay
    M-->>O: {success: true}
    
    O->>LLM: Generate response with tool result
    LLM-->>O: "Super ! Je t'affiche une vid√©o explicative..."
    
    O->>TTS: Synthesize response
    TTS-->>O: audio_bytes
    
    O->>L: Stream audio response
    L->>K: Audio playback
    
    O->>DB: Log interaction
    DB-->>O: OK
```

**Latence totale :** ~600ms
- Audio buffer : 100ms
- STT : 200ms
- LLM : 150ms
- TTS : 150ms
- Network : ~50ms

---

## üöÄ D√©ploiement RunPod

### ‚ö†Ô∏è Note importante : Docker vs Dockerless

**RunPod ne supporte PAS le Docker Compose nativement.** On a 2 options :

1. **‚úÖ RECOMMAND√â : D√©ploiement Dockerless** (ce qu'on va faire)
2. ‚ùå Image Docker all-in-one (plus complexe)

### Configuration Pod RunPod

**Sp√©cifications :**
```yaml
Name: jarvis-voice-engine-prod
GPU: NVIDIA A10 24GB
vCPU: 8 cores
RAM: 64GB
Storage: 100GB
Cloud Type: SECURE (datacenter)
Template: RunPod PyTorch (Ubuntu 22.04 + CUDA 12.1)
Ports expos√©s:
  - 3000 (Frontend)
  - 8000 (Backend API)
  - 8001 (MCP Tools)
```

**Co√ªt :** $0.39/h = **$281/mois** en continu

---

### Architecture des services (sans Docker)

```
RunPod Pod (Ubuntu 22.04 + CUDA 12.1)
‚îú‚îÄ‚îÄ Frontend (Next.js) - Port 3000
‚îú‚îÄ‚îÄ Backend (FastAPI + JARVIS) - Port 8000
‚îú‚îÄ‚îÄ STT Service (Kyutai) - 2.5GB VRAM
‚îú‚îÄ‚îÄ TTS Service (Kyutai) - 5.3GB VRAM
‚îú‚îÄ‚îÄ LLM Service (VLLM/Groq) - 6.1GB VRAM
‚îú‚îÄ‚îÄ MCP Tools Server - Port 8001
‚îî‚îÄ‚îÄ Redis (cache) - Port 6379

Total VRAM: ~14GB / 24GB disponibles
```

---

### Script de d√©ploiement RunPod

**`setup_jarvis_voice.sh`** (√† ex√©cuter dans le pod RunPod)

```bash
#!/bin/bash
set -e

echo "üöÄ JARVIS Voice Engine - Installation sur RunPod"

# 1. Installation des d√©pendances syst√®me
echo "üì¶ Installation des d√©pendances..."
apt-get update
apt-get install -y \
    curl \
    git \
    ffmpeg \
    redis-server \
    build-essential \
    pkg-config \
    libssl-dev

# 2. Installation uv (Python package manager)
echo "üêç Installation uv..."
curl -LsSf https://astral.sh/uv/install.sh | sh
export PATH="$HOME/.cargo/bin:$PATH"

# 3. Installation cargo (Rust - pour STT/TTS)
echo "ü¶Ä Installation cargo..."
curl https://sh.rustup.rs -sSf | sh -s -- -y
source $HOME/.cargo/env

# 4. Installation pnpm (Node.js package manager)
echo "üì¶ Installation pnpm..."
curl -fsSL https://get.pnpm.io/install.sh | sh -
export PNPM_HOME="$HOME/.local/share/pnpm"
export PATH="$PNPM_HOME:$PATH"

# 5. Clone Unmute (base de JARVIS Voice Engine)
echo "üì• Clone du repo Unmute..."
cd /workspace
git clone https://github.com/kyutai-labs/unmute.git jarvis-voice-engine
cd jarvis-voice-engine

# 6. Checkout version stable
git checkout main

# 7. Configuration Hugging Face (pour t√©l√©charger les mod√®les)
echo "ü§ó Configuration Hugging Face..."
export HUGGING_FACE_HUB_TOKEN="$HUGGING_FACE_TOKEN"

# 8. Build des services
echo "üî® Build des services..."
./dockerless/build_all.sh

# 9. T√©l√©chargement des mod√®les IA
echo "üì• T√©l√©chargement des mod√®les (peut prendre 10-15min)..."
uv run python unmute/download_models.py

# 10. Configuration JARVIS Extensions
echo "‚öôÔ∏è Configuration JARVIS..."
mkdir -p unmute/jarvis_extensions

# Cr√©er fichier de config
cat > unmute/jarvis_extensions/config.py << 'EOF'
import os

SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_SERVICE_ROLE_KEY")
MCP_TOOLS_PORT = 8001
REDIS_URL = "redis://localhost:6379"
EOF

# 11. D√©marrer Redis
echo "üî¥ D√©marrage Redis..."
redis-server --daemonize yes

# 12. Cr√©er systemd services (ou supervisor)
echo "üîß Configuration des services..."
cat > /etc/systemd/system/jarvis-frontend.service << 'EOF'
[Unit]
Description=JARVIS Frontend
After=network.target

[Service]
Type=simple
User=root
WorkingDirectory=/workspace/jarvis-voice-engine
ExecStart=/workspace/jarvis-voice-engine/dockerless/start_frontend.sh
Restart=always

[Install]
WantedBy=multi-user.target
EOF

cat > /etc/systemd/system/jarvis-backend.service << 'EOF'
[Unit]
Description=JARVIS Backend
After=network.target redis.service

[Service]
Type=simple
User=root
WorkingDirectory=/workspace/jarvis-voice-engine
Environment="SUPABASE_URL=${SUPABASE_URL}"
Environment="SUPABASE_SERVICE_ROLE_KEY=${SUPABASE_KEY}"
ExecStart=/workspace/jarvis-voice-engine/dockerless/start_backend.sh
Restart=always

[Install]
WantedBy=multi-user.target
EOF

cat > /etc/systemd/system/jarvis-stt.service << 'EOF'
[Unit]
Description=JARVIS STT
After=network.target

[Service]
Type=simple
User=root
WorkingDirectory=/workspace/jarvis-voice-engine
ExecStart=/workspace/jarvis-voice-engine/dockerless/start_stt.sh
Restart=always

[Install]
WantedBy=multi-user.target
EOF

cat > /etc/systemd/system/jarvis-tts.service << 'EOF'
[Unit]
Description=JARVIS TTS
After=network.target

[Service]
Type=simple
User=root
WorkingDirectory=/workspace/jarvis-voice-engine
ExecStart=/workspace/jarvis-voice-engine/dockerless/start_tts.sh
Restart=always

[Install]
WantedBy=multi-user.target
EOF

cat > /etc/systemd/system/jarvis-llm.service << 'EOF'
[Unit]
Description=JARVIS LLM
After=network.target

[Service]
Type=simple
User=root
WorkingDirectory=/workspace/jarvis-voice-engine
Environment="HUGGING_FACE_HUB_TOKEN=${HUGGING_FACE_TOKEN}"
ExecStart=/workspace/jarvis-voice-engine/dockerless/start_llm.sh
Restart=always

[Install]
WantedBy=multi-user.target
EOF

# 13. Reload systemd et d√©marrer les services
systemctl daemon-reload
systemctl enable jarvis-frontend jarvis-backend jarvis-stt jarvis-tts jarvis-llm
systemctl start jarvis-frontend jarvis-backend jarvis-stt jarvis-tts jarvis-llm

echo "‚úÖ Installation termin√©e !"
echo ""
echo "üéØ Services accessibles sur :"
echo "  - Frontend: http://localhost:3000"
echo "  - Backend API: http://localhost:8000"
echo "  - MCP Tools: http://localhost:8001"
echo ""
echo "üìä V√©rifier le status des services :"
echo "  systemctl status jarvis-*"
echo ""
echo "üìù Logs en temps r√©el :"
echo "  journalctl -u jarvis-backend -f"
```

---

### Variables d'environnement RunPod

√Ä configurer dans le pod RunPod :

```bash
# Supabase
export SUPABASE_URL="https://vurnokaxnvittopqteno.supabase.co"
export SUPABASE_SERVICE_ROLE_KEY="eyJhbGc..."

# Hugging Face (pour t√©l√©charger mod√®les)
export HUGGING_FACE_TOKEN="hf_..."

# OpenAI (optionnel, pour tests)
export OPENAI_API_KEY="sk-..."

# Groq (optionnel, si on veut utiliser Groq au lieu de VLLM local)
export GROQ_API_KEY="gsk_..."
```

---

## üîÑ Migration depuis OpenAI

### Phase 1 : Feature Flag

**Impl√©mentation :**
```typescript
// jarvis-saas-compagnon/src/lib/voiceConfig.ts
export const VOICE_PROVIDER = process.env.NEXT_PUBLIC_VOICE_PROVIDER || 'openai';

export const getVoiceConfig = () => {
  switch (VOICE_PROVIDER) {
    case 'openai':
      return {
        endpoint: 'https://api.openai.com/v1/realtime',
        model: 'gpt-4o-mini-realtime-preview',
      };
    case 'jarvis':
      return {
        endpoint: process.env.JARVIS_VOICE_ENGINE_URL,
        wsEndpoint: process.env.LIVEKIT_WS_URL,
      };
    default:
      throw new Error('Invalid voice provider');
  }
};
```

**Variables d'environnement :**
```env
# Vercel Environment Variables
NEXT_PUBLIC_VOICE_PROVIDER=openai  # ou "jarvis"

# JARVIS Voice Engine
JARVIS_VOICE_ENGINE_URL=https://jarvis-voice.runpod.io
LIVEKIT_WS_URL=wss://jarvis-voice.runpod.io:7880
LIVEKIT_API_KEY=jarvis-api-key
LIVEKIT_API_SECRET=secret-token
```

---

### Phase 2 : Adaptation frontend

**Modifications n√©cessaires :**

1. **Remplacer `useVoiceChat.ts` :**

```typescript
// src/hooks/useVoiceChat.ts (AVANT - OpenAI)
const pc = new RTCPeerConnection()
const realtimeResponse = await fetch(
  'https://api.openai.com/v1/realtime',
  { headers: { Authorization: `Bearer ${ephemeralKey}` } }
)

// (APR√àS - JARVIS)
import { Room, RoomEvent } from 'livekit-client'

const room = new Room()
await room.connect(LIVEKIT_WS_URL, token)

room.on(RoomEvent.TrackSubscribed, (track) => {
  if (track.kind === 'audio') {
    const audioElement = track.attach()
    document.body.appendChild(audioElement)
  }
})
```

2. **Nouveau hook `useJarvisVoice.ts` :**

```typescript
// src/hooks/useJarvisVoice.ts
import { Room } from 'livekit-client'

export const useJarvisVoice = (sessionId: string) => {
  const [room, setRoom] = useState<Room | null>(null)
  const [status, setStatus] = useState<'idle' | 'connecting' | 'connected'>('idle')

  const connect = async () => {
    // Cr√©er session
    const { token } = await fetch('/api/jarvis/session/create', {
      method: 'POST',
      body: JSON.stringify({ sessionId, badgeId, gymSlug }),
    }).then(r => r.json())

    // Connecter LiveKit
    const newRoom = new Room()
    await newRoom.connect(LIVEKIT_WS_URL, token)
    setRoom(newRoom)
    setStatus('connected')
  }

  const disconnect = async () => {
    await room?.disconnect()
    setRoom(null)
  }

  return { connect, disconnect, status, room }
}
```

3. **Nouvelle API route :**

```typescript
// src/app/api/jarvis/session/create/route.ts
export async function POST(req: Request) {
  const { sessionId, badgeId, gymSlug } = await req.json()

  // Fetch member profile
  const member = await supabase
    .from('gym_members')
    .select('*')
    .eq('badge_id', badgeId)
    .single()

  // Create session on JARVIS Voice Engine
  const response = await fetch(`${JARVIS_VOICE_ENGINE_URL}/session/create`, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      session_id: sessionId,
      member_id: member.id,
      gym_slug: gymSlug,
      context: {
        member: member,
        gym: gymData,
        weather: weatherData,
        datetime: new Date().toISOString(),
      },
    }),
  })

  const { livekit_token } = await response.json()

  return Response.json({ token: livekit_token })
}
```

---

### Phase 3 : Tests A/B

**Strat√©gie de rollout :**

```typescript
// Rollout progressif par salle
const JARVIS_ROLLOUT_GYMS = [
  'gym-test-1',  // Phase 1 : 1 salle test
  'gym-test-2',  // Phase 2 : 2 salles
  // ... progressif jusqu'√† 100%
]

export const shouldUseJarvis = (gymSlug: string) => {
  return JARVIS_ROLLOUT_GYMS.includes(gymSlug)
}
```

**M√©triques √† suivre :**
- Latence moyenne (objectif : < 500ms)
- Taux d'erreur (objectif : < 1%)
- Satisfaction utilisateur (feedback)
- Co√ªt par session

---

## üîí S√©curit√© et performance

### S√©curit√©

| Mesure | Impl√©mentation |
|--------|----------------|
| **Authentification** | JWT tokens (Supabase Auth) |
| **Encryption** | TLS 1.3 pour tous transports |
| **Rate limiting** | Redis-based (100 req/min/gym) |
| **API Keys** | Rotation mensuelle, secrets Vercel |
| **Network isolation** | Docker network priv√© |
| **Logs** | Pas de donn√©es sensibles logg√©es |

### Performance

**Optimisations :**
- ‚úÖ **Batching audio** : Buffers de 100ms
- ‚úÖ **Prefetch context** : Cache Redis
- ‚úÖ **Model caching** : Warm models en RAM
- ‚úÖ **Connection pooling** : DB connections r√©utilis√©es
- ‚úÖ **CDN** : Vid√©os tuto sur Supabase Storage + CDN

**Monitoring :**
```yaml
# Prometheus metrics
jarvis_voice_latency_seconds{stage="stt"} 0.2
jarvis_voice_latency_seconds{stage="llm"} 0.15
jarvis_voice_latency_seconds{stage="tts"} 0.15
jarvis_voice_sessions_active 12
jarvis_voice_errors_total{type="timeout"} 3
```

---

## üí∞ Co√ªts et scalabilit√©

### Co√ªts d√©taill√©s

**RunPod A10 24GB :**
- Instance : $0.39/h = $281/mois
- Bandwidth : $0.08/GB = ~$20/mois (estim√©)
- **Total infrastructure : ~$300/mois**

**APIs externes :**
- Groq LLM : $0.59/M tokens
  - Estimation : 50 tokens/interaction √ó 10k interactions/mois = 500k tokens
  - **Co√ªt : ~$0.30/mois** (n√©gligeable !)

**Comparaison OpenAI :**
- OpenAI Realtime : $18/h √ó 730h = **$13,140/mois** (5 kiosques actifs 24/7)
- JARVIS Voice Engine : **$300/mois**
- **√âconomie : $12,840/mois (97.7% de r√©duction !)**

### Scalabilit√©

**Scaling vertical (1 instance) :**
- 1 A10 24GB peut g√©rer : **~20 sessions simultan√©es**
- Latence reste < 500ms jusqu'√† 15 sessions

**Scaling horizontal (multi-instances) :**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         Load Balancer (Nginx)               ‚îÇ
‚îÇ              Port 443                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ              ‚îÇ              ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Instance  ‚îÇ  ‚îÇ  Instance  ‚îÇ  ‚îÇ Instance ‚îÇ
    ‚îÇ   #1 A10   ‚îÇ  ‚îÇ   #2 A10   ‚îÇ  ‚îÇ  #3 A10  ‚îÇ
    ‚îÇ  20 sess   ‚îÇ  ‚îÇ  20 sess   ‚îÇ  ‚îÇ 20 sess  ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Total : 60 sessions simultan√©es
Co√ªt : $900/mois (vs $39k OpenAI)
```

**Autoscaling :** Possible via RunPod API + Kubernetes

---

## üìÖ Plan de d√©ploiement

### Phase 0 : Pr√©paration (3 jours)

**Jour 1 :**
- [x] Architecture document√©e
- [ ] Cr√©er repo Git `jarvis-voice-engine`
- [ ] Setup RunPod account + billing
- [ ] Commander GPU A10 24GB

**Jour 2 :**
- [ ] Dockerfile + docker-compose.yml
- [ ] Scripts t√©l√©chargement mod√®les
- [ ] Configuration LiveKit

**Jour 3 :**
- [ ] Build image Docker
- [ ] Test local sur machine dev (CPU mode)
- [ ] Push image Docker Hub

---

### Phase 1 : MVP Fonctionnel (5 jours)

**Objectif :** Version basique qui fonctionne end-to-end

**Jour 4-5 :**
- [ ] FastAPI orchestrator
- [ ] Int√©gration Faster-Whisper
- [ ] Int√©gration Groq LLM
- [ ] Int√©gration Kokoro TTS

**Jour 6-7 :**
- [ ] LangGraph state machine
- [ ] MCP Tools server (3 tools basiques)
- [ ] Redis cache

**Jour 8 :**
- [ ] D√©ploiement sur RunPod
- [ ] Tests end-to-end
- [ ] Mesure latence

---

### Phase 2 : Int√©gration Frontend (3 jours)

**Jour 9-10 :**
- [ ] Hook `useJarvisVoice.ts`
- [ ] API route `/api/jarvis/session/create`
- [ ] Feature flag `VOICE_PROVIDER`
- [ ] Adaptateur LiveKit client

**Jour 11 :**
- [ ] Tests sur kiosque test
- [ ] Fix bugs UX
- [ ] Validation latence < 500ms

---

### Phase 3 : Tests Pilote (2 semaines)

**Semaine 1 :**
- [ ] D√©ployer sur 1 salle test (gym-test-1)
- [ ] Monitoring 24/7
- [ ] Collecter feedback adh√©rents

**Semaine 2 :**
- [ ] Ajuster prompts IA
- [ ] Optimiser latence
- [ ] Rollout sur 2 salles suppl√©mentaires

---

### Phase 4 : Production (1 mois)

**Mois 1 :**
- [ ] Rollout progressif (10% ‚Üí 50% ‚Üí 100%)
- [ ] Dashboard monitoring (Grafana)
- [ ] Documentation technique finale
- [ ] Formation √©quipe support

---

## ‚úÖ Checklist de validation

### Avant d√©ploiement production

- [ ] Latence moyenne < 500ms
- [ ] Taux d'erreur < 1%
- [ ] Tests de charge (20 sessions simultan√©es)
- [ ] Backup et disaster recovery plan
- [ ] Documentation API compl√®te
- [ ] Monitoring et alertes configur√©s
- [ ] Feature flag pr√™t (rollback instantan√©)

### Crit√®res de succ√®s

- [ ] √âconomie co√ªts > 90% vs OpenAI
- [ ] Satisfaction adh√©rents ‚â• 4.5/5
- [ ] Aucun incident critique
- [ ] Latence per√ßue = OpenAI ou mieux

---

## üìö Ressources

### Documentation

- [LiveKit Docs](https://docs.livekit.io/)
- [LangGraph Docs](https://langchain-ai.github.io/langgraph/)
- [Groq API](https://console.groq.com/docs)
- [Faster-Whisper](https://github.com/SYSTRAN/faster-whisper)
- [Kokoro TTS](https://github.com/hexgrad/kokoro)
- [MCP Protocol](https://modelcontextprotocol.io/)

### Repos GitHub

- `jarvis-voice-engine` (√† cr√©er)
- `jarvis-mcp-tools` (√† cr√©er)

---

**üöÄ Pr√™t √† d√©marrer l'impl√©mentation ?**

**Next step :** Phase 0 - Pr√©paration infrastructure

