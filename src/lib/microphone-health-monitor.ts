import { getSupabaseSingleton } from '@/lib/supabase-singleton'

// Types pour le monitoring microphone
interface MicrophoneMetrics {
  level: number
  quality: 'excellent' | 'good' | 'degraded' | 'poor'
  timestamp: Date
  isActive: boolean
  errorCount: number
}

interface MicrophoneHealthResult {
  status: 'healthy' | 'warning' | 'critical' | 'unknown'
  score: number // 0-100
  issues: string[]
  recommendations: string[]
  lastMetrics?: MicrophoneMetrics
}

interface MicrophoneAlert {
  id: string
  gymId: string
  kioskSlug: string
  severity: 'low' | 'medium' | 'high' | 'critical'
  message: string
  details: string
  timestamp: Date
  resolved: boolean
}

class MicrophoneHealthMonitor {
  private supabase = getSupabaseSingleton()
  private monitoringInterval: NodeJS.Timeout | null = null
  private isMonitoring = false

  /**
   * D√©marre le monitoring en temps r√©el du microphone
   */
  startMonitoring(gymId: string, kioskSlug: string, intervalMs: number = 30000) {
    if (this.isMonitoring) {
      console.warn('Monitoring d√©j√† actif')
      return
    }

    this.isMonitoring = true
    console.log(`üé§ [MONITORING] D√©marrage monitoring microphone pour ${kioskSlug}`)

    this.monitoringInterval = setInterval(async () => {
      try {
        await this.checkMicrophoneHealth(gymId, kioskSlug)
      } catch (error) {
        console.error('Erreur monitoring microphone:', error)
      }
    }, intervalMs)
  }

  /**
   * Arr√™te le monitoring
   */
  stopMonitoring() {
    if (this.monitoringInterval) {
      clearInterval(this.monitoringInterval)
      this.monitoringInterval = null
    }
    this.isMonitoring = false
    console.log('üé§ [MONITORING] Monitoring microphone arr√™t√©')
  }

  /**
   * V√©rifie la sant√© du microphone
   */
  async checkMicrophoneHealth(gymId: string, kioskSlug: string): Promise<MicrophoneHealthResult> {
    try {
      // 1. R√©cup√©rer les m√©triques r√©centes (5 derni√®res minutes)
      const { data: recentMetrics, error } = await this.supabase
        .from('kiosk_metrics')
        .select('microphone_level, audio_quality, collected_at, browser_info')
        .eq('gym_id', gymId)
        .eq('kiosk_slug', kioskSlug)
        .gte('collected_at', new Date(Date.now() - 5 * 60 * 1000).toISOString())
        .order('collected_at', { ascending: false })
        .limit(10)

      if (error) {
        throw error
      }

      // 2. Analyser la sant√© du microphone
      const healthResult = this.analyzeMicrophoneHealth(recentMetrics || [])

      // 3. Cr√©er des alertes si n√©cessaire
      if (healthResult.status === 'critical' || healthResult.status === 'warning') {
        await this.createMicrophoneAlert(gymId, kioskSlug, healthResult)
      }

      // 4. Enregistrer le r√©sultat du monitoring
      await this.recordHealthCheck(gymId, kioskSlug, healthResult)

      return healthResult

    } catch (error) {
      console.error('Erreur monitoring microphone:', error)
      return {
        status: 'unknown',
        score: 0,
        issues: ['Erreur de monitoring'],
        recommendations: ['V√©rifiez la connexion √† la base de donn√©es']
      }
    }
  }

  /**
   * Analyse les m√©triques pour d√©terminer la sant√© du microphone
   */
  private analyzeMicrophoneHealth(metrics: any[]): MicrophoneHealthResult {
    if (metrics.length === 0) {
      return {
        status: 'critical',
        score: 0,
        issues: ['Aucune m√©trique microphone r√©cente'],
        recommendations: [
          'V√©rifiez que le kiosque est en ligne',
          'Red√©marrez le kiosque si n√©cessaire'
        ]
      }
    }

    const issues: string[] = []
    const recommendations: string[] = []
    let score = 100

    // Analyser le niveau du microphone
    const avgLevel = metrics.reduce((sum, m) => sum + (m.microphone_level || 0), 0) / metrics.length
    if (avgLevel < 10) {
      issues.push('Niveau microphone tr√®s faible')
      recommendations.push('V√©rifiez que le microphone n\'est pas coup√©')
      score -= 30
    } else if (avgLevel < 30) {
      issues.push('Niveau microphone faible')
      recommendations.push('Ajustez le volume du microphone')
      score -= 15
    }

    // Analyser la qualit√© audio
    const poorQualityCount = metrics.filter(m => m.audio_quality === 'poor').length
    const degradedQualityCount = metrics.filter(m => m.audio_quality === 'degraded').length
    
    if (poorQualityCount > metrics.length * 0.5) {
      issues.push('Qualit√© audio d√©grad√©e')
      recommendations.push('V√©rifiez l\'environnement sonore et le mat√©riel')
      score -= 25
    } else if (degradedQualityCount > metrics.length * 0.3) {
      issues.push('Qualit√© audio variable')
      recommendations.push('R√©duisez le bruit ambiant')
      score -= 10
    }

    // Analyser la continuit√© des m√©triques
    const timeGaps = this.findTimeGaps(metrics)
    if (timeGaps.length > 0) {
      issues.push('Interruptions dans les m√©triques')
      recommendations.push('V√©rifiez la stabilit√© de la connexion')
      score -= 20
    }

    // D√©terminer le statut global
    let status: MicrophoneHealthResult['status'] = 'healthy'
    if (score < 30) status = 'critical'
    else if (score < 60) status = 'warning'
    else if (score < 85) status = 'warning'

    return {
      status,
      score: Math.max(0, score),
      issues,
      recommendations,
      lastMetrics: metrics[0] ? {
        level: metrics[0].microphone_level || 0,
        quality: metrics[0].audio_quality || 'unknown',
        timestamp: new Date(metrics[0].collected_at),
        isActive: true,
        errorCount: 0
      } : undefined
    }
  }

  /**
   * Trouve les gaps temporels dans les m√©triques
   */
  private findTimeGaps(metrics: any[]): { start: Date; end: Date; duration: number }[] {
    const gaps: { start: Date; end: Date; duration: number }[] = []
    const expectedInterval = 30000 // 30 secondes

    for (let i = 0; i < metrics.length - 1; i++) {
      const current = new Date(metrics[i].collected_at)
      const next = new Date(metrics[i + 1].collected_at)
      const gap = current.getTime() - next.getTime()

      if (gap > expectedInterval * 2) { // Gap > 1 minute
        gaps.push({
          start: next,
          end: current,
          duration: gap
        })
      }
    }

    return gaps
  }

  /**
   * Cr√©e une alerte microphone
   */
  private async createMicrophoneAlert(
    gymId: string, 
    kioskSlug: string, 
    healthResult: MicrophoneHealthResult
  ): Promise<void> {
    try {
      const severity = healthResult.status === 'critical' ? 'critical' : 'medium'
      
      const alert: Omit<MicrophoneAlert, 'id'> = {
        gymId,
        kioskSlug,
        severity,
        message: `Probl√®me microphone d√©tect√© (score: ${healthResult.score}/100)`,
        details: JSON.stringify({
          issues: healthResult.issues,
          recommendations: healthResult.recommendations,
          timestamp: new Date().toISOString()
        }),
        timestamp: new Date(),
        resolved: false
      }

      // V√©rifier si une alerte similaire existe d√©j√†
      const { data: existingAlerts } = await this.supabase
        .from('jarvis_errors_log')
        .select('id')
        .eq('gym_slug', kioskSlug)
        .eq('error_type', 'microphone_health')
        .eq('resolved', false)
        .gte('timestamp', new Date(Date.now() - 60 * 60 * 1000).toISOString()) // 1 heure

      if (!existingAlerts || existingAlerts.length === 0) {
        // Cr√©er nouvelle alerte
        await this.supabase
          .from('jarvis_errors_log')
          .insert({
            error_type: 'microphone_health',
            error_details: alert.message,
            gym_slug: kioskSlug,
            metadata: {
              severity: alert.severity,
              health_result: healthResult,
              alert_details: alert.details
            },
            resolved: false
          })

        console.log(`üö® [MONITORING] Alerte microphone cr√©√©e pour ${kioskSlug}`)
      }

    } catch (error) {
      console.error('Erreur cr√©ation alerte microphone:', error)
    }
  }

  /**
   * Enregistre le r√©sultat du check de sant√©
   */
  private async recordHealthCheck(
    gymId: string, 
    kioskSlug: string, 
    healthResult: MicrophoneHealthResult
  ): Promise<void> {
    try {
      await this.supabase
        .from('system_logs')
        .insert({
          log_type: 'health',
          message: `Microphone health check: ${healthResult.status} (score: ${healthResult.score}/100)`,
          details: {
            gym_id: gymId,
            kiosk_slug: kioskSlug,
            health_result: healthResult,
            timestamp: new Date().toISOString()
          }
        })

    } catch (error) {
      console.error('Erreur enregistrement health check:', error)
    }
  }

  /**
   * R√©cup√®re l'historique de sant√© du microphone
   */
  async getMicrophoneHealthHistory(
    gymId: string, 
    kioskSlug: string, 
    hours: number = 24
  ): Promise<MicrophoneHealthResult[]> {
    try {
      const { data: logs, error } = await this.supabase
        .from('system_logs')
        .select('message, details, timestamp')
        .eq('log_type', 'health')
        .gte('timestamp', new Date(Date.now() - hours * 60 * 60 * 1000).toISOString())
        .order('timestamp', { ascending: false })

      if (error) throw error

      return logs?.map(log => log.details?.health_result).filter(Boolean) || []

    } catch (error) {
      console.error('Erreur r√©cup√©ration historique:', error)
      return []
    }
  }

  /**
   * Test en temps r√©el du microphone
   */
  async testMicrophoneRealtime(): Promise<MicrophoneMetrics> {
    try {
      if (!navigator.mediaDevices?.getUserMedia) {
        throw new Error('getUserMedia non support√©')
      }

      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
          sampleRate: 16000
        }
      })

      // Analyser le niveau audio
      const audioContext = new AudioContext()
      const source = audioContext.createMediaStreamSource(stream)
      const analyser = audioContext.createAnalyser()
      source.connect(analyser)

      const dataArray = new Uint8Array(analyser.frequencyBinCount)
      analyser.getByteFrequencyData(dataArray)
      
      const level = Math.max(...dataArray)
      let quality: MicrophoneMetrics['quality'] = 'excellent'
      
      if (level < 10) quality = 'poor'
      else if (level < 30) quality = 'degraded'
      else if (level < 60) quality = 'good'

      // Nettoyer
      stream.getTracks().forEach(track => track.stop())
      audioContext.close()

      return {
        level,
        quality,
        timestamp: new Date(),
        isActive: true,
        errorCount: 0
      }

    } catch (error: any) {
      return {
        level: 0,
        quality: 'poor',
        timestamp: new Date(),
        isActive: false,
        errorCount: 1
      }
    }
  }
}

// Instance singleton
export const microphoneHealthMonitor = new MicrophoneHealthMonitor()

// Fonctions utilitaires
export const startMicrophoneMonitoring = (gymId: string, kioskSlug: string) => {
  microphoneHealthMonitor.startMonitoring(gymId, kioskSlug)
}

export const stopMicrophoneMonitoring = () => {
  microphoneHealthMonitor.stopMonitoring()
}

export const checkMicrophoneHealth = (gymId: string, kioskSlug: string) => {
  return microphoneHealthMonitor.checkMicrophoneHealth(gymId, kioskSlug)
}

export const getMicrophoneHealthHistory = (gymId: string, kioskSlug: string, hours?: number) => {
  return microphoneHealthMonitor.getMicrophoneHealthHistory(gymId, kioskSlug, hours)
}

export const testMicrophoneRealtime = () => {
  return microphoneHealthMonitor.testMicrophoneRealtime()
}

