/**
 * üéôÔ∏è TYPES COMMUNS - VOICE REALTIME SYSTEM
 * 
 * Types partag√©s entre kiosk et vitrine pour le syst√®me vocal
 * 
 * @version 1.0.0
 * @date 2025-01-XX
 */

/**
 * Statut de la connexion vocale
 */
export type VoiceStatus = 
  | 'idle' 
  | 'connecting' 
  | 'connected' 
  | 'listening' 
  | 'speaking' 
  | 'error' 
  | 'reconnecting'

/**
 * Session OpenAI Realtime
 */
export interface VoiceSession {
  /** Client secret pour authentification WebRTC */
  client_secret: { value: string } | string
  /** ID de session OpenAI */
  session_id: string
  /** Date d'expiration */
  expires_at: string
}

/**
 * Factory pour cr√©er des sessions vocales
 * 
 * Permet de s√©parer la logique de cr√©ation de session (kiosk vs vitrine)
 * du code WebRTC commun
 */
export interface VoiceSessionFactory {
  /**
   * Cr√©er une nouvelle session vocale
   * 
   * @returns Session OpenAI Realtime avec credentials
   * @throws Error si la cr√©ation √©choue
   */
  createSession(): Promise<VoiceSession>
}

/**
 * √âtat audio pour le hook kiosk
 * 
 * Note: Diff√©rent de AudioState dans types/kiosk.ts
 * Ce type est sp√©cifique au syst√®me vocal Realtime
 */
export interface VoiceAudioState {
  /** L'utilisateur est en train de parler */
  isListening: boolean
  /** JARVIS est en train de r√©pondre */
  isPlaying: boolean
  /** Volume audio (0-100) */
  volume: number
  /** Transcription actuelle */
  transcript: string
  /** Transcription finale (non modifiable) */
  isFinal: boolean
}

/**
 * Configuration audio pour getUserMedia
 */
export interface AudioConfig {
  /** Taux d'√©chantillonnage (Hz) - Standard OpenAI: 16000 */
  sampleRate?: number
  /** Annulation d'√©cho */
  echoCancellation?: boolean
  /** Suppression de bruit */
  noiseSuppression?: boolean
  /** Contr√¥le automatique du gain */
  autoGainControl?: boolean
  /** Nombre de canaux (1 = mono, 2 = st√©r√©o) */
  channelCount?: number
  /** Latence cible (secondes) */
  latency?: number
  /** Volume (0.0 - 1.0) */
  volume?: number
}

/**
 * √âv√©nement de function call OpenAI
 */
export interface FunctionCallEvent {
  /** ID de l'appel */
  call_id: string
  /** Nom de la fonction */
  name: string
  /** Arguments (JSON string) */
  arguments: string
}

/**
 * Configuration du core Realtime
 */
export interface VoiceRealtimeCoreConfig {
  /** Factory pour cr√©er la session (sp√©cifique au contexte) */
  sessionFactory: VoiceSessionFactory
  
  /** Configuration audio */
  audioConfig?: AudioConfig
  
  /** Callback changement de statut */
  onStatusChange?: (status: VoiceStatus) => void
  
  /** Callback mise √† jour transcription */
  onTranscriptUpdate?: (transcript: string, isFinal?: boolean) => void
  
  /** Callback erreur */
  onError?: (error: Error) => void
  
  /** Callback changement √©tat audio (pour kiosk) */
  onAudioStateChange?: (state: VoiceAudioState) => void
  
  /** Callback function call d√©tect√© */
  onFunctionCall?: (call: FunctionCallEvent, dataChannel: RTCDataChannel) => void
  
  /** Callback session cr√©√©e */
  onSessionCreated?: (sessionId: string) => void
  
  /** Contexte (pour logging diff√©renci√©) */
  context?: 'kiosk' | 'vitrine'
}

/**
 * Retour du hook core Realtime
 */
export interface VoiceRealtimeCoreReturn {
  /** √âtat de connexion */
  isConnected: boolean
  
  /** Statut actuel */
  status: VoiceStatus
  
  /** Connexion √† OpenAI Realtime */
  connect: () => Promise<void>
  
  /** D√©connexion */
  disconnect: () => Promise<void>
  
  /** Obtenir le data channel (pour function calls) */
  getDataChannel: () => RTCDataChannel | null
  
  /** Obtenir la peer connection (pour debugging) */
  getPeerConnection: () => RTCPeerConnection | null
  
  /** Obtenir l'ID de session */
  getSessionId: () => string | null
}

