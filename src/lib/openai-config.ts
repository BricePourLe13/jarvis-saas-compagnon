/**
 * üéôÔ∏è CONFIGURATION CENTRALIS√âE OPENAI REALTIME
 * 
 * IMPORTANT:
 * - Tous les mod√®les et configurations audio sont d√©finis ici
 * - Les valeurs par d√©faut utilisent les derniers mod√®les stables (2025)
 * - Modifiable via variables d'environnement pour flexibilit√©
 * 
 * USAGE:
 * ```typescript
 * import { OPENAI_CONFIG } from '@/lib/openai-config'
 * 
 * const sessionConfig = {
 *   model: OPENAI_CONFIG.models.production,
 *   voice: OPENAI_CONFIG.voices.production,
 *   // ...
 * }
 * ```
 * 
 * @version 2.0.0
 * @date 2025-10-22
 */

export const OPENAI_CONFIG = {
  /**
   * ü§ñ MOD√àLES REALTIME
   * 
   * - production: Optimis√© co√ªt/qualit√© pour usage quotidien
   * - vitrine: Meilleure qualit√© pour d√©mos commerciales
   * - audio: Mod√®le sp√©cialis√© audio (√† tester)
   */
  models: {
    /**
     * Mod√®le production (kiosques, app mobile)
     * - Mini = optimis√© co√ªt
     * - Bonne qualit√© pour fitness coaching
     * - Latence <800ms
     */
    production: process.env.OPENAI_REALTIME_MODEL_PROD || 'gpt-realtime-mini-2025-10-06',
    
    /**
     * Mod√®le vitrine (d√©mos commerciales, landing page)
     * - Full = meilleure qualit√©
     * - Latence <600ms
     * - Impression professionnelle
     */
    vitrine: process.env.OPENAI_REALTIME_MODEL_VITRINE || 'gpt-realtime-2025-08-28',
    
    /**
     * Mod√®le audio sp√©cialis√© (√† √©valuer)
     * - Potentiellement optimis√© pour audio-only
     * - √Ä tester pour co√ªt/qualit√©
     */
    audio: process.env.OPENAI_REALTIME_MODEL_AUDIO || 'gpt-audio-2025-08-28',
  },

  /**
   * üé§ VOIX TTS
   * 
   * Voix test√©es et valid√©es pour le fran√ßais:
   * - verse: Optimis√©e fran√ßais (naturelle, expressive)
   * - alloy: Voix masculine √©nergique (alternative)
   * - ballad, coral, sage: Autres options (√† tester)
   */
  voices: {
    /**
     * Voix production
     * - verse = voix fran√ßaise optimis√©e
     * - Ton naturel et bienveillant pour coaching
     */
    production: (process.env.OPENAI_VOICE_PROD || 'verse') as OpenAIVoice,
    
    /**
     * Voix vitrine
     * - alloy = voix masculine dynamique
     * - Ton commercial et √©nergique
     */
    vitrine: (process.env.OPENAI_VOICE_VITRINE || 'alloy') as OpenAIVoice,
    
    /**
     * Voix fallback (si voix principale indisponible)
     */
    fallback: (process.env.OPENAI_VOICE_FALLBACK || 'alloy') as OpenAIVoice,
  },

  /**
   * üéß CONFIGURATION AUDIO
   * 
   * Format optimis√© pour WebRTC et faible latence
   */
  audio: {
    /**
     * Format d'entr√©e (microphone)
     * - pcm16 = 16-bit PCM (standard WebRTC)
     * - 16kHz mono
     */
    inputFormat: 'pcm16' as const,
    
    /**
     * Format de sortie (haut-parleurs)
     * - pcm16 = 16-bit PCM (standard WebRTC)
     * - 16kHz mono
     */
    outputFormat: 'pcm16' as const,
    
    /**
     * Taux d'√©chantillonnage
     * - 16kHz = bon compromis qualit√©/bande passante
     * - Compatible avec tous les navigateurs modernes
     */
    sampleRate: 16000,
  },

  /**
   * üéôÔ∏è VOICE ACTIVITY DETECTION (VAD)
   * 
   * Configuration server-side VAD pour d√©tection de parole
   */
  vad: {
    /**
     * Type de VAD
     * - server_vad = d√©tection c√¥t√© serveur OpenAI (recommand√©)
     * - √âvite la charge CPU client
     */
    type: 'server_vad' as const,
    
    /**
     * Seuil de d√©tection
     * - 0.5 = √©quilibr√© (ni trop sensible, ni trop sourd)
     * - Range: 0.0 (tr√®s sensible) √† 1.0 (tr√®s sourd)
     */
    threshold: 0.5,
    
    /**
     * Padding avant la parole (ms)
     * - 300ms = capture le d√©but de mots
     * - √âvite de couper le premier phon√®me
     */
    prefixPaddingMs: 300,
    
    /**
     * Dur√©e de silence pour fin de tour (PRODUCTION)
     * - 500ms = r√©actif pour coaching fitness
     * - Bon compromis vitesse/confort
     */
    silenceDurationMs: 500,
    
    /**
     * Dur√©e de silence pour fin de tour (D√âMO/VITRINE)
     * - 1200ms = plus tol√©rant pour h√©sitations commerciales
     * - √âvite interruptions g√™nantes en d√©mo
     */
    silenceDurationMsDemo: 1200,
    
    /**
     * Autoriser interruptions utilisateur
     * - true = utilisateur peut couper JARVIS (naturel)
     * - false = JARVIS finit toujours sa phrase
     */
    interruptResponse: true,
    
    /**
     * Cr√©er r√©ponse automatiquement apr√®s d√©tection
     * - true = LLM g√©n√®re r√©ponse d√®s silence d√©tect√©
     * - false = requiert trigger manuel (pas recommand√©)
     */
    createResponse: true,
  },

  /**
   * üì° URLS API OPENAI
   */
  api: {
    /**
     * URL cr√©ation session ephemeral
     */
    sessions: 'https://api.openai.com/v1/realtime/sessions',
    
    /**
     * URL WebRTC realtime (avec query param model)
     */
    realtime: 'https://api.openai.com/v1/realtime',
    
    /**
     * Header beta requis pour API Realtime
     */
    betaHeader: 'realtime=v1',
  },

  /**
   * ‚öôÔ∏è CONFIGURATION SESSION PAR D√âFAUT
   * 
   * Utilis√© comme base pour toutes les sessions
   */
  session: {
    /**
     * Temp√©rature du LLM
     * - 0.8 = cr√©atif sans √™tre trop al√©atoire
     * - Range: 0.0 (d√©terministe) √† 2.0 (tr√®s cr√©atif)
     */
    temperature: 0.8,
    
    /**
     * Tokens max de sortie
     * - 4096 = permet r√©ponses d√©taill√©es si besoin
     * - JARVIS reste concis naturellement (via instructions)
     */
    maxResponseOutputTokens: 4096,
    
    /**
     * Mod√®le de transcription (STT int√©gr√©)
     * - whisper-1 = mod√®le OpenAI Whisper standard
     * - Tr√®s bon pour le fran√ßais
     */
    transcriptionModel: 'whisper-1',
  },
} as const

/**
 * üé≠ TYPES TYPESCRIPT
 */

/**
 * Voix disponibles dans OpenAI Realtime API
 * 
 * Source: https://platform.openai.com/docs/guides/realtime
 * 
 * - alloy: Voix neutre, √©nergique
 * - ash: Voix masculine mature (nouvelle)
 * - ballad: Voix douce, chaleureuse
 * - coral: Voix f√©minine expressive
 * - echo: Voix masculine (classique)
 * - sage: Voix m√ªre, autoritaire
 * - shimmer: Voix douce, calme
 * - verse: Voix optimis√©e fran√ßais (recommand√©e FR)
 */
export type OpenAIVoice = 
  | 'alloy'
  | 'ash'
  | 'ballad'
  | 'coral'
  | 'echo'
  | 'sage'
  | 'shimmer'
  | 'verse'

/**
 * Mod√®les Realtime disponibles
 */
export type OpenAIRealtimeModel = 
  | 'gpt-realtime-2025-08-28'           // Full - haute qualit√©
  | 'gpt-realtime-mini-2025-10-06'      // Mini - optimis√© co√ªt
  | 'gpt-audio-2025-08-28'              // Audio sp√©cialis√©

/**
 * Types de contexte (production vs vitrine)
 */
export type OpenAIContext = 'production' | 'vitrine' | 'audio'

/**
 * üîß HELPER FUNCTIONS
 */

/**
 * R√©cup√©rer configuration pour un contexte sp√©cifique
 * 
 * @param context Type de session (production, vitrine, audio)
 * @returns Configuration compl√®te pour ce contexte
 * 
 * @example
 * ```typescript
 * const config = getConfigForContext('production')
 * // config.model = 'gpt-realtime-mini-2025-10-06'
 * // config.voice = 'verse'
 * // config.vad.silenceDurationMs = 500
 * ```
 */
export function getConfigForContext(context: OpenAIContext) {
  const isDemo = context === 'vitrine'
  
  return {
    model: OPENAI_CONFIG.models[context],
    voice: context === 'production' ? OPENAI_CONFIG.voices.production : OPENAI_CONFIG.voices.vitrine,
    input_audio_format: OPENAI_CONFIG.audio.inputFormat,
    output_audio_format: OPENAI_CONFIG.audio.outputFormat,
    turn_detection: {
      type: OPENAI_CONFIG.vad.type,
      threshold: OPENAI_CONFIG.vad.threshold,
      prefix_padding_ms: OPENAI_CONFIG.vad.prefixPaddingMs,
      silence_duration_ms: isDemo ? OPENAI_CONFIG.vad.silenceDurationMsDemo : OPENAI_CONFIG.vad.silenceDurationMs,
      interrupt_response: OPENAI_CONFIG.vad.interruptResponse,
      create_response: OPENAI_CONFIG.vad.createResponse,
    },
    input_audio_transcription: {
      model: OPENAI_CONFIG.session.transcriptionModel,
    },
    temperature: OPENAI_CONFIG.session.temperature,
    max_response_output_tokens: OPENAI_CONFIG.session.maxResponseOutputTokens,
  }
}

/**
 * Construire URL WebRTC avec mod√®le
 * 
 * @param context Type de session
 * @returns URL compl√®te pour connexion WebRTC
 * 
 * @example
 * ```typescript
 * const url = getRealtimeURL('production')
 * // 'https://api.openai.com/v1/realtime?model=gpt-realtime-mini-2025-10-06'
 * ```
 */
export function getRealtimeURL(context: OpenAIContext): string {
  const model = OPENAI_CONFIG.models[context]
  return `${OPENAI_CONFIG.api.realtime}?model=${model}`
}

/**
 * V√©rifier si un mod√®le est disponible
 * 
 * @param model Nom du mod√®le √† v√©rifier
 * @returns true si mod√®le valide
 */
export function isValidModel(model: string): model is OpenAIRealtimeModel {
  const validModels: OpenAIRealtimeModel[] = [
    'gpt-realtime-2025-08-28',
    'gpt-realtime-mini-2025-10-06',
    'gpt-audio-2025-08-28',
  ]
  return validModels.includes(model as OpenAIRealtimeModel)
}

/**
 * V√©rifier si une voix est disponible
 * 
 * @param voice Nom de la voix √† v√©rifier
 * @returns true si voix valide
 */
export function isValidVoice(voice: string): voice is OpenAIVoice {
  const validVoices: OpenAIVoice[] = [
    'alloy', 'ash', 'ballad', 'coral', 'echo', 'sage', 'shimmer', 'verse'
  ]
  return validVoices.includes(voice as OpenAIVoice)
}

/**
 * üìä MONITORING HELPERS
 */

/**
 * Extraire version du mod√®le pour analytics
 * 
 * @param model Nom complet du mod√®le
 * @returns Version format√©e (ex: "2025-10", "2025-08")
 * 
 * @example
 * ```typescript
 * getModelVersion('gpt-realtime-mini-2025-10-06') // '2025-10'
 * getModelVersion('gpt-realtime-2025-08-28')      // '2025-08'
 * ```
 */
export function getModelVersion(model: string): string {
  const match = model.match(/(\d{4})-(\d{2})/)
  return match ? `${match[1]}-${match[2]}` : 'unknown'
}

/**
 * D√©terminer le tier du mod√®le pour analytics
 * 
 * @param model Nom complet du mod√®le
 * @returns Tier ('mini', 'full', 'audio', 'unknown')
 */
export function getModelTier(model: string): 'mini' | 'full' | 'audio' | 'unknown' {
  if (model.includes('mini')) return 'mini'
  if (model.includes('audio')) return 'audio'
  if (model.includes('realtime')) return 'full'
  return 'unknown'
}

/**
 * üîí VALIDATION RUNTIME
 * 
 * V√©rifier configuration au d√©marrage
 */
export function validateConfig(): { valid: boolean; errors: string[] } {
  const errors: string[] = []

  // V√©rifier mod√®les
  if (!isValidModel(OPENAI_CONFIG.models.production)) {
    errors.push(`Invalid production model: ${OPENAI_CONFIG.models.production}`)
  }
  if (!isValidModel(OPENAI_CONFIG.models.vitrine)) {
    errors.push(`Invalid vitrine model: ${OPENAI_CONFIG.models.vitrine}`)
  }
  if (!isValidModel(OPENAI_CONFIG.models.audio)) {
    errors.push(`Invalid audio model: ${OPENAI_CONFIG.models.audio}`)
  }

  // V√©rifier voix
  if (!isValidVoice(OPENAI_CONFIG.voices.production)) {
    errors.push(`Invalid production voice: ${OPENAI_CONFIG.voices.production}`)
  }
  if (!isValidVoice(OPENAI_CONFIG.voices.vitrine)) {
    errors.push(`Invalid vitrine voice: ${OPENAI_CONFIG.voices.vitrine}`)
  }
  if (!isValidVoice(OPENAI_CONFIG.voices.fallback)) {
    errors.push(`Invalid fallback voice: ${OPENAI_CONFIG.voices.fallback}`)
  }

  // V√©rifier VAD
  if (OPENAI_CONFIG.vad.threshold < 0 || OPENAI_CONFIG.vad.threshold > 1) {
    errors.push(`Invalid VAD threshold: ${OPENAI_CONFIG.vad.threshold} (must be 0-1)`)
  }

  return {
    valid: errors.length === 0,
    errors,
  }
}

// üöÄ Validation au chargement du module (dev only)
if (process.env.NODE_ENV === 'development') {
  const validation = validateConfig()
  if (!validation.valid) {
    console.warn('‚ö†Ô∏è OPENAI_CONFIG validation errors:', validation.errors)
  } else {
    console.log('‚úÖ OPENAI_CONFIG validated successfully')
    console.log('üìã Models:', OPENAI_CONFIG.models)
    console.log('üé§ Voices:', OPENAI_CONFIG.voices)
  }
}

